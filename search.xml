<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>聊聊AB实验（2）——AB实验</title>
    <url>/2022/05/04/20220503-%E8%81%8A%E8%81%8AAB%E5%AE%9E%E9%AA%8C%EF%BC%882%EF%BC%89%E2%80%94%E2%80%94AB%E5%AE%9E%E9%AA%8C/</url>
    <content><![CDATA[<h1 id="AB实验"><a href="#AB实验" class="headerlink" title="AB实验"></a>AB实验</h1><h2 id="AB实验的定义"><a href="#AB实验的定义" class="headerlink" title="AB实验的定义"></a>AB实验的定义</h2><p>在上一篇章，我们谈到了AA实验（也叫自然实验），同时我们说到了AA实验最大的问题是存在内生性问题。而解决这一问题的方案，则是我们今天要讲的AB实验。</p>
<p>关于AB实验的定义，相信有各个互联网大佬给出过类似的定义。实际上在我看来，所谓AB实验，就是我们在学术界（尤其是在医学领域）经常提到的随机化实验。随机化实验，是指为了测试某一个策略的有效性，通过随机分流的方式，将用户分成实验组和对照组，并对实验组用户施加需要测试的策略，最终通过比较实验组和对照组之间在某些效应的不同来证明策略是否有效的一种实验方法。<strong>这种实验方法对于实验设计这一步骤非常严苛，要保证在实验前实验组和对照组之间的各个因素间几乎是相同的</strong>。由于在实验前已经控制了各变量对实验结果的影响，因此在实验中不存在内生性的问题。</p>
<p><strong>也正因如此严苛的实验方法，通过这一方式，我们能直接导出策略与因变量之间的因果性</strong>（一般都是只能测量相关性）。</p>
<blockquote>
<p>注：在这里提的策略实际上是指对照组与实验组的不同点，并非狭义的策略含义</p>
</blockquote>
<h2 id="AB实验的设计"><a href="#AB实验的设计" class="headerlink" title="AB实验的设计"></a>AB实验的设计</h2><p>在前面的定义部分有提到，AB实验的核心在于实验的设计部分。而一个实验的设计需要做到明确以下几个问题：</p>
<ul>
<li>实验本身的目的。我们做AB实验，其目的是想要给用户带来什么样的价值，或者是想要验证某一些问题。我们需要根据实验的目的，提出实验假设。</li>
<li>实验指标的选择。实验指标的选择与我们的实验的目的息息相关，我们实验假设直接决定了我们要用什么样的指标去量化它。</li>
<li>实验组设计。为了达到我们实验的目的，我们需要多少个实验组，每对实验组比较的目的是什么。</li>
<li>实验流量的计算。为了测量出实验指标的显著性，我们应该至少需要多少流量，才能够在最小化对用户影响的情况下测试出对用户的影响。</li>
<li>实验周期问题。为了达到实验目的，回收我们的实验，我们应当在多少时间内回收。</li>
</ul>
<p>考虑好上述问题后，我们在做实验时才能够做到心中有数，在实验分析时，才能把握住主要脉络。</p>
<h2 id="AB实验的分析"><a href="#AB实验的分析" class="headerlink" title="AB实验的分析"></a>AB实验的分析</h2><p>AB实验最主要的思想就是假设检验。在实验满足回收周期后，通过观察我们实验指标是否显著来决策我们的假设是否成立。</p>
<p>咦，就这么简单吗？没错，就是这么简单。但是为什么平时我们在做实验分析的时候会感觉这么复杂没有说的这么简单呢？<strong>这是因为上面所说的，都只是涉及到单指标的实验分析，而我们平时遇到的，是多指标的实验分析</strong>。</p>
<p><strong>在业界，我们常常发现，一个app，尤其是功能复杂的app，对于一个功能的改动，很容易带来蝴蝶效应，引起很多个指标的同时变化</strong>。比如我的实验目的是想要在某英语学习app主页位置多放一个收藏按钮，我们实验设计观测的指标是收藏率，但实际上这个收藏按钮引起的反应可能是收藏率提升，带动用户学习次数和时长变多，最终带来用户留存上的提升。</p>
<p>我的leader，我的同事们常常告诉我说要时刻区分什么叫数据现象什么叫数据结论，他们说数据分析师要做的工作，能够为业务方输出数据结论而不是单纯的描述数据现象。<strong>实际上所谓的数据结论就是要为这些多个同时变化的指标构建影响的逻辑链条（或者叫层级关系）</strong>。以上面的收藏按钮改动的实验为例，实际上我们的影响链路可以归结为</p>
<p><pre class="mermaid">flowchart TD<br>x1(“收藏率”)<br>x2(“用户学习次数”)<br>x3(“用户学习时长”)<br>x4(“用户留存”)</p>
<p>x1—&gt;|+|x2;<br>x1—&gt;|+|x3;<br>x2—&gt;|+|x4;<br>x3—&gt;|+|x4;&lt;/pre&gt;</p>
<blockquote>
<p>“+”表示同向影响</p>
</blockquote>
<p>另一方面，在逻辑链条梳理的过程中，我们还需要警惕另外一点：多重比较问题</p>
<h2 id="AB实验拓展：多重比较问题"><a href="#AB实验拓展：多重比较问题" class="headerlink" title="AB实验拓展：多重比较问题"></a>AB实验拓展：多重比较问题</h2><p>多重比较实际上涉及到两方面的问题，一是实验组之间的多重比较问题，二是实验指标之间的多重比较问题。</p>
<p>对于第一个问题，顾名思义，即实验组数过多，可能会导致部分实验指标偶然显著，例如，某交互实验开了31个实验组，对于同一个指标而言，假如该指标不应该发生变化，那么在置信度为5\%的情况下，不存在任何一个实验组犯第一类错误的概率为$(1-5\%)^{31}$，可以想象，这个值是非常小的。</p>
<p>对于第二个问题，即我们要观测的指标数很多，那么对于不应该显著的指标而言（假设有$x$个），这些指标不犯第一类错误的概率为$(1-5\%)^{x}$，这样一来，除非实验能影响的指标非常多，并且找到明确的逻辑链路，否则犯第一类错误的概率随着$x$的增大而增大。我们数据分析师，也需要具备排除这些偶然显著指标的能力。</p>
<h1 id="AB实验示例"><a href="#AB实验示例" class="headerlink" title="AB实验示例"></a>AB实验示例</h1><p>前面说了很多基本概念和思想，这里简单实操一下AB实验，还是沿用上面的收藏按钮的例子。</p>
<p>实验设计部分：</p>
<ul>
<li>实验目的：通过多增加一个收藏按钮，增强用户的收藏意愿，用户收藏数量变多，其学习的欲望也会随之增强，进而带来学习时长提升的目的。</li>
<li>实验指标：<ul>
<li>收藏率、人均学习时长、人均学习次数</li>
<li>最核心指标计算指标为收藏率，预期提升30\%</li>
</ul>
</li>
<li>实验组设计：对照组（保持线上）、实验组（有收藏按钮）</li>
<li>流量计算：根据置信度5\%、统计功效80\%，以及收藏率的均值和方差，计算出单组流量5\%即可</li>
<li>实验周期：7天</li>
</ul>
<p>实验结果：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>实验组别</th>
<th>收藏率</th>
<th>人均学习时长</th>
<th>人均学习次数</th>
<th>用户留存</th>
</tr>
</thead>
<tbody>
<tr>
<td>实验组</td>
<td>x1（正向显著）</td>
<td>x2（正向显著）</td>
<td>x3（正向显著）</td>
<td>x4（正向显著）</td>
</tr>
<tr>
<td>对照组</td>
<td>y1</td>
<td>y2</td>
<td>y3</td>
<td>y4</td>
</tr>
</tbody>
</table>
</div>
<p>找到影响链路：</p>
<ul>
<li>收藏按钮引起的反应可能是收藏率提升，带动用户学习次数和时长变多，最终带来用户留存上的提升。</li>
</ul>
]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>A/B 实验</tag>
      </tags>
  </entry>
  <entry>
    <title>聊聊AB实验（1）——AA实验</title>
    <url>/2022/05/03/20220503-%E8%81%8A%E8%81%8AAB%E5%AE%9E%E9%AA%8C%EF%BC%881%EF%BC%89%E2%80%94%E2%80%94AA%E5%AE%9E%E9%AA%8C/</url>
    <content><![CDATA[<h1 id="前言：客户端发版的数据分析"><a href="#前言：客户端发版的数据分析" class="headerlink" title="前言：客户端发版的数据分析"></a>前言：客户端发版的数据分析</h1><p>在互联网数据分析的工作中，一个较为例行的任务就是保障客户端发版。为了避免客户端存在bug对用户有较多的打扰，一般在客户端发版时，都会经历灰度阶段。灰度，其实就是小批量测试的过程。整个保障过程，除了RD、QA以外，数据分析师也得参与其中。QA可以介入测试功能，那数据分析师的作用是什么呢？数据分析师，<strong>就是要比较客户端版本升级前和升级后在某些核心指标上是否存在明显变化</strong>。</p>
<p>假设我们现在有一个英语学习类app正在发版（例如从v1.0.0升级到v1.1.0），对于新用户而言，我们关注的核心指标是人均学习时长，两个版本的新用户人均学习时长曲线如下</p>
<p><img src="../images/AA%20analysis/learning_time.png" alt="avatar"></p>
<p>那么要比较两个版本之间的差异，只需要将两条曲线做差/做比即可。如果两条曲线的差值没有稳定下降且没有回升的趋势，那么我们就认定这个版本大概率是没有问题的；反之，如果核心指标的差异随着天数的增加一直稳定下降没有回升的趋势，说明这个版本可能存在着一定的问题，这个问题或者是某些功能的改变带来的，也有可能是客户端出现了一定的bug。</p>
<p><img src="../images/AA%20analysis/learning_time_diff.png" alt="avatar"></p>
<p>接着上面的例子，两条曲线的差值在稳定下降，我们需要暴露这个问题进行排查。</p>
<h1 id="AA实验"><a href="#AA实验" class="headerlink" title="AA实验"></a>AA实验</h1><h2 id="AA实验的定义"><a href="#AA实验的定义" class="headerlink" title="AA实验的定义"></a>AA实验的定义</h2><p>前面的例子已经让大家对AA实验有了一定的了解。<strong>在我看来，AA实验实际上就是我们在学术里经常提到的自然实验</strong>。所谓自然实验，就是让实验组的用户，在受到环境等非实验观测者控制的因素作用下，自然地进入到实验组（对照组和实验组用户对于其在哪一组并不知情），并受实验观测者观测的一类研究方法。</p>
<blockquote>
<p>严格来说自然实验是不允许实验用户知道自己是在实验组里还是对照组里的，在互联网环境下可以做到。但是对于学术界，比如我们评估政策有效性时，我们也会用自然实验的研究方法来进行研究。</p>
</blockquote>
<p>例如前面的例子中，对于新用户而言，什么样的用户以及什么时候注册和使用app我们无法控制，用户在使用后能知晓其所在的app版本，但他们并不知道我们在研究这一行为或者在做这类实验。</p>
<h2 id="AA实验的应用场景"><a href="#AA实验的应用场景" class="headerlink" title="AA实验的应用场景"></a>AA实验的应用场景</h2><p>在互联网场景下，目前我遇到比较多的AA实验应用场景如下：</p>
<ul>
<li>搞了xxx活动（比如春晚直播转播），活动周期为y天，想要评估下活动的效果</li>
<li>运营模式以社群为主，但社群数量少，社群运营周期长，实验成本高。调整了运营策略，如何评价策略的有效性</li>
<li>发布了新的客户端版本，想要评价本次发版有没有引起重大的bug/对客户端做的优化策略是否有效</li>
</ul>
<p>这些场景的主要特点：</p>
<ul>
<li><strong>实验成本高或实验条件不足</strong>。实验成本高主要指金钱成本或机会成本，比如上述第一类问题，运营活动需要花费大量的宣传费、物料费用以及人力成本。如果在这些活动上开随机实验的话，一方面前期的投入就会打水漂（沉默成本），另一方面，原本在用户侧能获取到的收益现在也无法获取（机会成本）；实验条件不足主要指现有场景不满足实验的应具备的条件，最常见的是样本量不足的条件。</li>
<li>大多和时间因素相关。比如第一个问题，如果要应用AA分析，实际上就是要比较活动前与活动后实验指标的差异。这一对比是由时间来提供的。</li>
</ul>
<h2 id="AA实验的常用研究方法"><a href="#AA实验的常用研究方法" class="headerlink" title="AA实验的常用研究方法"></a>AA实验的常用研究方法</h2><p>这一块实际涉及涉及的不多，我就所了解的方法简单说明一下，针对某些特定的方法，可能会单独在用某些篇章专门说明。</p>
<h3 id="做差-做比比较法"><a href="#做差-做比比较法" class="headerlink" title="做差/做比比较法"></a>做差/做比比较法</h3><p>这一方法我感觉是最常用的，比如前面提到的发版的例子，在控制好协变量后，将前后的观测值做差或者做比，观察差值或比值的变化情况</p>
<h3 id="双重差分"><a href="#双重差分" class="headerlink" title="双重差分"></a>双重差分</h3><p>这一方法通常固定某一时间节点，各选取实验前和实验后一段时间的观测值，在组内和组间做差，最终比较两次差分的结果。实际上做差/做比比较法就是双重差分的一种特例。</p>
<h3 id="因果推断"><a href="#因果推断" class="headerlink" title="因果推断"></a>因果推断</h3><p>既然没有办法做随机实验，那么可以通过结果人群人为的构造一组近似随机的实验组和对照组，并比较两组之间的处理效应。在互联网常用的方法有IPW、CEM两种，PSM目前见使用得不多</p>
<h2 id="AA实验的问题"><a href="#AA实验的问题" class="headerlink" title="AA实验的问题"></a>AA实验的问题</h2><p>AA实验（或者叫自然实验）并不是万能的，这种实验方式存在着一些问题，不然无论是学术界还是业界，为什么都没有过分推崇这一实验方法。总结下来其最大问题在于<strong>内生性问题</strong>。这一问题几乎是自然实验最大的一类问题，由于自然实验是用户自然暴露在实验条件内，也就是说，实验组和对照组用户可能在某些影响实验结果的因素上并不完全相同。<strong>这些因素有可能和人口统计学因素有关，也有可能跟用户自身的属性有关，跟外界环境因素有关，甚至会和时间因素有关</strong>。因为我们没办法完全剔除内生性的影响，因此用这种方式进行归因，会存在一定的缺陷。<strong>但如果我们有较为明确的逻辑链路，某些情况下使用这种方式进行归因是没有问题的。</strong></p>
<blockquote>
<p>内生性问题示例：<br>比如我们在发版时要比较老用户在新版本与旧版本核心指标上的差异，我们可能会发现新版本的部分指标会远高于老版本。而这个结果可能并不是版本变化带来的，而是因为发版过程中愿意升级新版本的用户可能是app的忠实用户（如高活用户），因此这个是活跃度差异导致的指标变化。</p>
</blockquote>
<h2 id="AA实验的替代品"><a href="#AA实验的替代品" class="headerlink" title="AA实验的替代品"></a>AA实验的替代品</h2><p>因为AA实验存在着内生性这一弊端，因此在互联网业界，我们会更推崇使用另一种方式：AB实验。具体AB实验是什么，我们放到之后的篇章进行讲解</p>
]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>A/B 实验</tag>
      </tags>
  </entry>
  <entry>
    <title>20211205_Bayesian Data Analysis（四）：假设检验</title>
    <url>/2021/12/05/20211205-Bayesian-Data-Analysis%EF%BC%88%E5%9B%9B%EF%BC%89%EF%BC%9A%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/</url>
    <content><![CDATA[<h1 id="贝叶斯假设检验简介"><a href="#贝叶斯假设检验简介" class="headerlink" title="贝叶斯假设检验简介"></a>贝叶斯假设检验简介</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>在统计学课程中讲授的一般是频率学派下假设检验的方法，事实上在贝叶斯推断里也存在着假设检验这一套方法。在贝叶斯推断中，一个基本观点是“条件方法”。回想之前提到过的，给定一个先验分布$p(\theta$，我们可以通过抽样信息，求出后验分布$p(\theta \mid y)$，而贝叶斯推断框架下，进行统计推断的最主要依据，就是我们的后验分布$p(\theta \mid y)$。</p>
<h2 id="两个概念"><a href="#两个概念" class="headerlink" title="两个概念"></a>两个概念</h2><h3 id="最大似然估计（Maximum-Likelihood-Estimate-MLE）"><a href="#最大似然估计（Maximum-Likelihood-Estimate-MLE）" class="headerlink" title="最大似然估计（Maximum Likelihood Estimate, MLE）"></a>最大似然估计（Maximum Likelihood Estimate, MLE）</h3><p>假设我们观测到的样本$y=\{y_{1}, \cdots, y_{n}\}$，我们的采样分布为$p(y\mid \theta)$，那么对总体参数最好的估计，就是似然函数取值最大时的参数值</p>
<script type="math/tex; mode=display">
\begin{align*}
\theta_{MLE}=\arg \max_{\theta} \prod_{i=1}^{n} p(y_{i}\mid \theta)
\end{align*}</script><h3 id="最大后验估计（Maximum-A-Posteriori-MAP）"><a href="#最大后验估计（Maximum-A-Posteriori-MAP）" class="headerlink" title="最大后验估计（Maximum A Posteriori, MAP）"></a>最大后验估计（Maximum A Posteriori, MAP）</h3><p>假设我们的先验分布为$p(\theta)$，总体采样分布为$p(y \mid \theta)$，最大后验分布，即使后验分布概率密度取值最大的参数值（恰好为后验分布的众数）</p>
<script type="math/tex; mode=display">
\begin{align*}
\theta_{MAP}
&=\arg \max_{\theta} \frac{p(\theta)p(y \mid \theta)}{\int_{\theta} p(\theta)p(y \mid \theta)}\\
&=\arg \max_{\theta} p(\theta \mid y)
\end{align*}</script><h1 id="点估计"><a href="#点估计" class="headerlink" title="点估计"></a>点估计</h1><p>正如简介里所讲的那样，贝叶斯推断的点估计与后验分布密切相关，最常用的三种点估计方式是<strong>最大后验估计、最大中位数估计和最大均值估计</strong>。在下文，不加说明的情况下，均以最大后验估计为基准</p>
<h2 id="频率学派-vs-贝叶斯学派"><a href="#频率学派-vs-贝叶斯学派" class="headerlink" title="频率学派 vs 贝叶斯学派"></a>频率学派 vs 贝叶斯学派</h2><p>在上学时，老师会告诉大家一个关于无偏性的概念，无偏性可以用如下数学表达式表示</p>
<script type="math/tex; mode=display">
\begin{align*}
E(\hat{\theta})=\int_{y} p(y)p(y\mid \theta) dy = \theta
\end{align*}</script><p>从含义上看，无偏性表示在多次实验中所得到的估计量的平均值与参数的真实值相吻合。</p>
<p>但实际上，无偏性只在频率学派的统计推断里出现，而在贝叶斯学派里没有出现，这是为什么呢？答案还得从两个学派的差异开始找起。</p>
<h3 id="频率学派"><a href="#频率学派" class="headerlink" title="频率学派"></a>频率学派</h3><p>在频率学派下，对参数的估计形式为$\hat{\theta}=\hat{\theta}(Y)$。这样的一种估计形式是<strong>以样本为基础</strong>的一个函数。但需要注意的是我们这里<strong>参数$Y$是随机变量而非样本，而$\theta$本身是一个固定的常数值而非随机变量</strong>。频率学派认为在对参数进行估计时，<strong>既要考虑我们的抽样信息($y$)，还要考虑未观测到的其他所有样本信息($\hat{y}$)</strong>。</p>
<p>在实际估计时，由于样本与总体是独立同分布的，因此样本可以代表总体带入到函数中进行拟合。</p>
<h3 id="贝叶斯学派"><a href="#贝叶斯学派" class="headerlink" title="贝叶斯学派"></a>贝叶斯学派</h3><p>贝叶斯学派下，对参数的估计形式为$\hat{\theta}=\hat{\theta}(y)$。这个估计形式表示贝叶斯推断是依赖于抽样信息，而与未观测到的抽样信息无关。也就是说<strong>参数$y$是一个样本，而$\theta$本身是一个关于该样本的随机变量</strong>。</p>
<p>回到我们之前的问题上来，无偏性只出现在频率学派中是因为<strong>需要考虑样本空间内所有可能的取值</strong>，也就是说无论是否在本次抽样中被采集到都需要去考虑。而在贝叶斯学派下则认为参数的取值仅跟当前的抽样信息有关</p>
<h2 id="两个例子"><a href="#两个例子" class="headerlink" title="两个例子"></a>两个例子</h2><p>例子来自于茆诗松老师的《贝叶斯统计》：</p>
<h3 id="例1：智商估计"><a href="#例1：智商估计" class="headerlink" title="例1：智商估计"></a>例1：智商估计</h3><p>假设儿童智力测验结果满足$p(y)=N(\theta, 100)$， 其中$\theta$被定义为儿童的智商，根据之前的多次实验，可以假设$p(\theta)=N(100, 225)$，加入我们现在 对一名儿童进行智力测验，希望能够得到这名儿童智商的估计，若儿童的测验分数为115分，结果是怎样的呢？</p>
<p><strong>频率学派的观点</strong><br>在频率学派的观点下，对这名儿童的智商$\theta$的最好估计实际上就是样本均值（用样本均值估计总体均值），即</p>
<script type="math/tex; mode=display">
\begin{align*}
\theta_{MLE}=\bar{y}=y=115
\end{align*}</script><p>进一步，其方差的最好估计即总体方差，即$\sigma^{2}=100$</p>
<p><strong>贝叶斯学派的观点</strong><br>此前提到过方差已知的情况下，正态分布的后验估计也是正态分布</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\theta \mid y) 
&\propto 
e^{-\frac{1}{2\sigma_{n}^{2}}(\theta-\mu_{n})^{2}}\\
\end{align*}</script><p>其中</p>
<script type="math/tex; mode=display">
\begin{align*}
\mu_{n} 
&= \frac{\frac{1}{\sigma_{0}^{2}}\mu_{0}+\frac{n}{\sigma^{2}}\bar{y}}{\frac{1}{\sigma_{0}^{2}}+\frac{n}{\sigma^{2}}}
\frac{1}{\sigma_{n}^{2}} = \gamma \mu_{0}+(1-\gamma)\bar{y}\\
\sigma_{n}^{2}&= \frac{1}{\sigma_{0}^{2}} + \frac{n}{\sigma^{2}}\\
\mu_{0}&=100\\
\sigma_{0}^{2}&=225\\
\sigma^{2}&=100\\
n&=1\\
\end{align*}</script><p>由正态分布的性质可知，最大后验估计即最大后验分布的均值处，即</p>
<script type="math/tex; mode=display">
\begin{align*}
\theta_{MAP}=\mu_{n} 
&= \frac{\frac{1}{\sigma_{0}^{2}}\mu_{0}+\frac{n}{\sigma^{2}}\bar{y}}{\frac{1}{\sigma_{0}^{2}}+\frac{n}{\sigma^{2}}}
\frac{1}{\sigma_{n}^{2}} = \frac{400+9y}{13}=110.38\\
\end{align*}</script><p>进一步，其方差的估计为</p>
<script type="math/tex; mode=display">
\begin{align*}
\sigma_{n}^{2}&= \frac{1}{\sigma_{0}^{2}} + \frac{n}{\sigma^{2}}=69.23\\
\end{align*}</script><p>从这个例子可以看出贝叶斯估计结合了先验信息、总体信息和抽样信息，修正了这名儿童的测试结果，而同时又修正了结果的方差，而频率学派则没有做出修正（因为它是站在总体的角度去看待问题）</p>
<h3 id="例2：不合格率估计"><a href="#例2：不合格率估计" class="headerlink" title="例2：不合格率估计"></a>例2：不合格率估计</h3><p>为估计不合格品率$\theta$，现从一批产品中随机抽取$n$件，设不合格件数$y$服从二项分布，在历史上常用$Beta(\alpha, \beta)$作为$\theta$的先验分布，为方便起见，假定为$Beta(1, 1)$。</p>
<p><strong>频率学派的观点</strong><br>在频率学派的观点下，不合格率$\theta$实际上是总体不合格情况的一个均值，而对总体均值的最好估计是样本均值，因此可以用样本均值来作为一个点估计。</p>
<p>另一种角度看，假设观测到的样本$y=\{y_{1}, \cdots, y_{n}\}$，通过最大似然估计，即求</p>
<script type="math/tex; mode=display">
\begin{align*}
\theta_{MLE}
&=\arg \max_{\theta} p(y\mid \theta)\\
&\propto \arg \max_{\theta}  \theta^{y}(1-\theta)^{n-y}\\
&=\frac{y}{n}
\end{align*}</script><p><strong>贝叶斯学派的观点</strong><br>在$Beta(1, 1)$的先验分布下（也就是$[0,1]$的均匀分布），假设观测到的样本$y=\{y_{1}, \cdots, y_{n}\}$，通过最大后验估计，我们有</p>
<script type="math/tex; mode=display">
\begin{align*}
\theta_{MAP}
&=\arg \max_{\theta} \frac{p(\theta)p(y \mid \theta)}{\int_{\theta} p(\theta)p(y \mid \theta)}\\
&\propto \arg \max_{\theta} p(\theta)p(y \mid \theta)\\
&\propto \arg \max_{\theta} \theta^{y}(1-\theta)^{n-y}\\
&=\frac{y}{n}
\end{align*}</script><h1 id="区间估计"><a href="#区间估计" class="headerlink" title="区间估计"></a>区间估计</h1><h2 id="频率学派-vs-贝叶斯学派-1"><a href="#频率学派-vs-贝叶斯学派-1" class="headerlink" title="频率学派 vs 贝叶斯学派"></a>频率学派 vs 贝叶斯学派</h2><h3 id="频率学派-1"><a href="#频率学派-1" class="headerlink" title="频率学派"></a>频率学派</h3><p>在频率学派下，设我们感兴趣的总体参数为$\theta$，其参数空间为$\Theta$，总体的一个样本为$y=\{y_{1}, \cdots, y_{n}\}$。对于任意给定的一个<strong>显著性水平$1-\alpha$</strong>，假设有两个统计量$\hat{\theta_{L}}=\hat{\theta_{L}}(y_{1}, \cdots, y_{n})$和$\hat{\theta_{U}}=\hat{\theta_{U}}(y_{1}, \cdots, y_{n})$，使得对于任意$\theta \in \Theta$，满足</p>
<script type="math/tex; mode=display">
\begin{align*}
Pr(\hat{\theta_{L}} \leq \theta \leq \hat{\theta_{U}}) \geq 1-\alpha
\end{align*}</script><p>那么我们称$[\hat{\theta_{L}}, \hat{\theta_{U}}]$是$\theta$的$1-\alpha$的<strong>置信区间</strong>，其中$\hat{\theta_{L}}$和$\hat{\theta_{U}}$分别被称为$\theta$的双侧<strong>置信下限和置信上限</strong>。</p>
<p>同理我们可以定义出<strong>单侧情况下的置信下限和置信上限</strong>。</p>
<p>常用的求解置信区间的方法为<strong>枢轴量法</strong>。</p>
<blockquote>
<p>枢轴量是样本和待估参数的函数，其分布不依赖于任何未知参数；(注意函数中只能含有待估参数，不能有其他未知参数)<br>枢轴量法的主要步骤</p>
<ol>
<li>从$\theta$的一个<strong>点估计</strong>出发，构造与$\theta$的一个函数$G$，使得$G$的分布（在大样本场合，可以是$G$的渐近分布）是已知的，而且与$\theta$无关。通常称这种函数为枢轴量。</li>
<li>适当选取两个常数$c_{1}$与$c_{2}$，使对给定的$\alpha$，有$Pr(c_{1} \leq G \leq c_{2})\geq 1-\alpha$ </li>
<li>利用不等式运算进行等价变形，使得最后能得到形如$\hat{\theta_{L}} \leq \theta \leq \hat{\theta_{U}}$的不等式。若这一切可能，则就是θ的置信区间。</li>
</ol>
</blockquote>
<p>对于置信区间$[\hat{\theta_{L}}, \hat{\theta_{U}}]$和显著性水平$1-\alpha$的一个频率解释是：</p>
<ul>
<li>在大量重复使用$\theta$的置信区间$[\hat{\theta_{L}}, \hat{\theta_{U}}]$时，每次获得的样本观测值是不同的，从而每次得到的区间也是不同的，<strong>但平均来看，在大量的区间估计观测值中，至少有$1-\alpha$的区间包含总体参数$\theta$</strong>。</li>
</ul>
<p>为什么使用这么难以理解的说法呢？这事因为在频率学派下，<strong>我们认为总体参数$\theta$是一个常量</strong>，对于$\theta$而言，它要么在$[\hat{\theta_{L}}, \hat{\theta_{U}}]$里，要么不在$[\hat{\theta_{L}}, \hat{\theta_{U}}]$，因此我们只能用上面的那种说法。但实际上在很多实际工作场合，很多时候我们是直接理解成$\theta$在$[\hat{\theta_{L}}, \hat{\theta_{U}}]$里的概率为$1-\alpha$</p>
<h3 id="贝叶斯学派-1"><a href="#贝叶斯学派-1" class="headerlink" title="贝叶斯学派"></a>贝叶斯学派</h3><p>贝叶斯学派下，我们对参数$\theta$的区间估计也是围绕后验分布$p(\theta \mid y)$进行的。设总体的一个样本为$y=\{y_{1}, \cdots, y_{n}\}$。对于任意给定的一个<strong>显著性水平$1-\alpha$</strong>，假设有两个统计量$\hat{\theta_{L}}=\hat{\theta_{L}}(y_{1}, \cdots, y_{n})$和$\hat{\theta_{U}}=\hat{\theta_{U}}(y_{1}, \cdots, y_{n})$，使得对于任意$\theta \in \Theta$，满足</p>
<script type="math/tex; mode=display">
\begin{align*}
Pr(\hat{\theta_{L}} \leq \theta \leq \hat{\theta_{U}} \mid y) \geq 1-\alpha
\end{align*}</script><blockquote>
<p>不知道大家有没有注意是在给定样本$y$的条件下</p>
</blockquote>
<p>那么我们称$[\hat{\theta_{L}}, \hat{\theta_{U}}]$是$\theta$的$1-\alpha$的贝叶斯<strong>可信区间</strong>，其中$\hat{\theta_{L}}$和$\hat{\theta_{U}}$分别被称为$\theta$的双侧<strong>可信下限和可信上限</strong>。同理我们可以定义出<strong>单侧情况下的可信下限和可信上限</strong>。</p>
<p>对于可信区间$[\hat{\theta_{L}}, \hat{\theta_{U}}]$和显著性水平$1-\alpha$的一个贝叶斯解释是：</p>
<ul>
<li>总体参数$\theta$落在区间$[\hat{\theta_{L}}, \hat{\theta_{U}}]$的概率为$1-\alpha$</li>
</ul>
<p>从解释上看，可信区间的解释程度明显比置信区间的解释更为直观自然</p>
<h2 id="可信区间的计算方式"><a href="#可信区间的计算方式" class="headerlink" title="可信区间的计算方式"></a>可信区间的计算方式</h2><p>不知道大家是否注意到，对于一个概率分布而言，面积为$1-\alpha$的区域可以有无数多个，我们不可能报告所有可能的区间，也不应该随意报告一个区间。那么我们在求解可信区间的时候应该采用什么样的方式进行呢？这里我们介绍两种方式，一种是等尾可信区间，另一种是最大后验密度置信区间。</p>
<h3 id="等尾可信区间"><a href="#等尾可信区间" class="headerlink" title="等尾可信区间"></a>等尾可信区间</h3><p>等尾可信区间的思想实质上非常简单，我们只需要在后验分布的左右两侧各找到面积为$\frac{\alpha}{2}$的分位点即可，用数学语言表示为</p>
<script type="math/tex; mode=display">
\begin{equation}
\left\{
\begin{aligned}
\int_{-\infty}^{\hat{\theta_{L}}} p(\theta \mid y)=\frac{\alpha}{2}\\
\int_{\hat{\theta_{U}}}^{\infty} p(\theta \mid y)=\frac{\alpha}{2}\\
\end{aligned}
\right.
\end{equation}</script><h3 id="最大后验密度可信区间"><a href="#最大后验密度可信区间" class="headerlink" title="最大后验密度可信区间"></a>最大后验密度可信区间</h3><p>等尾可信区间虽然常用，但是并不是最理想的状态，最理想的应该是让<strong>区间长度总和最短的可信区间的集合</strong>。假定这样的可信集为$C$，即保证</p>
<script type="math/tex; mode=display">
\begin{align*}
Pr(\theta \in C \mid y) &= 1-\alpha\\
p(\theta_{1} \mid y) &\geq p(\theta_{2} \mid y) \quad \forall \theta_{1} \in C, \theta_{2} \notin C
\end{align*}</script><p>要找到最大后验密度可信区间比较困难，一般采取迭代的方式进行求解（EM算法），在这里不做展开。</p>
<h1 id="假设检验"><a href="#假设检验" class="headerlink" title="假设检验"></a>假设检验</h1><p>在贝叶斯框架下处理假设检验问题有它的优势和劣势，优势在于其只需要根据后验分布的情况作出判断，而劣势在于对于部分假设，我们需要考虑其在连续性分布和离散型分布上的适用情况（比如$H_{0}: \theta = \{\theta_{0}\} \longleftrightarrow H_{1}: \theta = \{\theta_{1}\}$就只能针对于离散型随机变量进行，因为连续性随机变量单点的概率为0），为方便起见，在这里我们只考虑连续性随机变量适用的情形。</p>
<p>基本假设形式:</p>
<script type="math/tex; mode=display">
\begin{align*}
H_{0}: \theta \in \Theta_{0}\longleftrightarrow H_{1}: \theta \in \Theta_{1}
\end{align*}</script><h2 id="频率学派-2"><a href="#频率学派-2" class="headerlink" title="频率学派"></a>频率学派</h2><h3 id="经典假设检验的步骤"><a href="#经典假设检验的步骤" class="headerlink" title="经典假设检验的步骤"></a>经典假设检验的步骤</h3><p>在频率学派的观点下，对于假设检验问题一共有几个步骤：<br><strong>Step1</strong><br>只要我们根据我们的背景以及假设的信息构造检验统计量$T$，该统计量需要满足当$H_{0}$为真的时候，其分布完全已知。即当我们在总体中抽出一组样本$X=\{x_{1}, x_{2},\cdots, x_{n}\}$时，统计量$T$的值为已知状态<br><strong>Step2</strong><br>设定我们的置信度$\alpha$（为方便起见我们暂且只考虑置信度水平）<br><strong>Step3</strong><br>构建检验统计量$T$与拒绝域$W$之间的关系，当我们确定置信度水平后，我们容易知道拒绝域满足</p>
<script type="math/tex; mode=display">
\begin{align*}
Pr\{\mbox{reject }H_{0} \mid H_{0}\mbox{ is true}\} \leq \alpha
\end{align*}</script><p>根据上式进行变形，构造检验统计量$T$与拒绝域$W$之间的关系<br><strong>Step4</strong><br>在总体中抽出一组样本$X=\{x_{1}, x_{2},\cdots, x_{n}\}$，并代入上式进行计算，看是否落入拒绝域中，以此来判断是否拒绝$H_{0}$</p>
<p>在上述四个步骤里，我们所做的工作实际上就是在想尽办法去证明原假设是错误的，备择假设是值得可信的。<strong>因此，频率学派的假设检验的魅力重在如何拒绝原假设。</strong></p>
<h3 id="经典假设检验的问题"><a href="#经典假设检验的问题" class="headerlink" title="经典假设检验的问题"></a>经典假设检验的问题</h3><p>从上述的步骤可以看到，当我们不对统计功效$1-\beta$进行限制的时候，上述统计推断其实是在保护原假设$H_{0}$，因为我们其实可以容忍其犯第二类错误的概率（$\beta$）非常的高。也就是说，除非我们能够找到充分的理由，否则我们不应该拒绝$H_{0}$</p>
<blockquote>
<p>注：统计功效的计算公式</p>
<script type="math/tex; mode=display">
\begin{align*}
    \beta &= Pr\{\mbox{accept }H_{0} \mid H_{0}\mbox{ is not true}\}
\end{align*}</script></blockquote>
<h3 id="第一类错误和第二类错误的权衡"><a href="#第一类错误和第二类错误的权衡" class="headerlink" title="第一类错误和第二类错误的权衡"></a>第一类错误和第二类错误的权衡</h3><p>为了防止第二类错误的容忍度被无限的扩大，在实际使用时我们不仅考虑到第一类错误，同时还要考虑第二类错误所带来的原假设被保护的问题（因为如果不考虑这一问题，很多时候我们就没办法敏锐的发现我们是否该拒绝原假设）<br>但是第一类错误和第二类错误本身存在存在一定的置换关系，这点可以从统计功效的表达式里看出来：</p>
<script type="math/tex; mode=display">
\begin{align*}
    power &= 1-\beta\\
    &= 1 - \{\Phi(z_{1-\alpha / 2} - z) - \Phi(-z_{1-\alpha / 2} - z)\}\\
    &\approx 1 - \Phi(z_{1-\alpha / 2} - \vert z \vert)\\
    &= \Phi( \vert z \vert - z_{1-\alpha / 2})
\end{align*}</script><p>其中$z$是我们所构建的统计量。</p>
<p>为了解决这种置换关系，需要考虑犯第一类错误的危险性大还是第二类错误的危险性大，根据经验，我们一般取$\alpha=0.05$，$\beta=0.2$</p>
<h2 id="贝叶斯学派-2"><a href="#贝叶斯学派-2" class="headerlink" title="贝叶斯学派"></a>贝叶斯学派</h2><p>在贝叶斯学派下，假设检验相比于频率学派会更直观一些，在给定$\theta$的先验分布$p(\theta)$后，其后验分布满足</p>
<script type="math/tex; mode=display">
\begin{align*}
    p(\theta \mid y) &= \frac{p(\theta)p(y \mid \theta)}{p(y)}\\
    &\approx p(\theta)p(y \mid \theta)
\end{align*}</script><p>对于每一类假设，其区别在于$\theta$所在的参数空间不同，因此只需要根据后验分布以及假设的参数空间，计算出在每一类假设的参数空间内的后验概率，并比较两者的后验概率比的大小即可。</p>
<p>根据开头所提的假设检验问题，我们可以知道</p>
<script type="math/tex; mode=display">
\begin{align*}
    Pr_{0}(\theta \mid y)&=\int_{\Theta_{0}}p(\theta \mid y)\\
    Pr_{1}(\theta \mid y)&=\int_{\Theta_{1}}p(\theta \mid y)\\
    r&=\frac{Pr_{0}(\theta \mid y)}{Pr_{1}(\theta \mid y)}
\end{align*}</script><blockquote>
<p>当$\Theta$为离散型时，将积分换成求和</p>
</blockquote>
<p>当$r &lt; 1$ 时，说明备择假设是正确的，当$r &gt; 1$ 时，说明原假设是正确的，当$r = 1$ 时，说明要做支持原假设或备择假设的决策的信息尚未充足，此时有以下两种可能：</p>
<ul>
<li>增加样本的信息</li>
<li>增加先验分布的信息</li>
</ul>
<h3 id="贝叶斯因子"><a href="#贝叶斯因子" class="headerlink" title="贝叶斯因子"></a>贝叶斯因子</h3><p>我们假设</p>
<script type="math/tex; mode=display">
\begin{align*}
    Pr_{0}(\theta)&=\int_{\Theta_{0}}p(\theta)\\
    Pr_{1}(\theta )&=\int_{\Theta_{1}}p(\theta)\\
    r_{0}&=\frac{Pr_{0}(\theta)}{Pr_{1}(\theta)}
\end{align*}</script><p>那么贝叶斯因子$B^{\pi}$满足</p>
<script type="math/tex; mode=display">
\begin{align*}
    B^{\pi} = \frac{r}{r_{0}} = 
\end{align*}</script><p><strong>贝叶斯因子的含义：在样本信息加持的情况下，$H_{0}$被支持的程度的放大的倍数</strong></p>
<p>通常情况下，贝叶斯因子会和后验概率比一起来决策</p>
<h3 id="例3：不合格率估计"><a href="#例3：不合格率估计" class="headerlink" title="例3：不合格率估计"></a>例3：不合格率估计</h3><p>设不合格品率$\theta$，现从一批产品中随机抽取$n$件，设不合格件数$y$服从二项分布，在历史上常用$Beta(\alpha, \beta)$作为$\theta$的先验分布，为方便起见，假定为$Beta(1, 1)$。当$\theta \leq \alpha$时，产品可以出厂。即</p>
<script type="math/tex; mode=display">
\begin{align*}
H_{0}: \theta \leq 0.05 \longleftrightarrow H_{1}: \theta > 0.05
\end{align*}</script><h3 id="贝叶斯假设检验的问题"><a href="#贝叶斯假设检验的问题" class="headerlink" title="贝叶斯假设检验的问题"></a>贝叶斯假设检验的问题</h3><p>贝叶斯假设检验其实也存在一些问题（但受作者水平有限，目前只能理解其中一个问题）。<br><strong>问题一：当计算出$r$的大小后，我们没有充足的信心去决策哪个假设最好</strong></p>
<p>当我们的假设中的参数空间并不是整个样本空间的一个分隔时，满足$Pr_{0}(y)+Pr_{1}(y)\leq 1$。<br>我们假设$Pr_{0}(y)=0.01,Pr_{1}(y)=0.001$，此时$r=10$。这些数据分别表明，当我们的假设为$H_{0}$，我们认为该假设发生的后验概率为0.01，而当我们的假设为$H_{1}$，我们认为该假设发生的后验概率为0.001。从数据上看，虽然$H_{0}$要优于$H_{1}$，但$H_{0}$发生的概率也只有1\%，只要我们没有足够的信心能够去判断最终方案不是$H_{0}$就是$H_{1}$，那么我们就没有办法说$H_{0}$是该假设检验问题的最优解</p>
<p><strong>问题二：对于部分假设检验问题，贝叶斯假设检验的可解释性较差</strong></p>
<p>根据前面所述可以隐约知道，<strong>频率学派的观点是$\theta$为一个常数，而贝叶斯学派认为$\theta$为一个随机变量</strong>。对于如下形式假设检验问题，实际上贝叶斯假设检验的解释性会变得很弱</p>
<script type="math/tex; mode=display">
\begin{align*}
H_{0}: \theta = 0.8\longleftrightarrow H_{1}: \theta \neq 0.8
\end{align*}</script><p>我们假设这个问题是在考虑某实验组的次日留存率是否为0.8，在频率学派下，$\theta$为一个常数，这么假设非常自然。但是在贝叶斯假设检验下，因为$\theta$为一个随机变量，而且在本问题下还是个连续型随机变量，这样一来，原假设的概率始终为0（连续型随机变量的在单点处的概率为0），因此这样的假设是毫无意义的。</p>
<p>为了解决这一问题，贝叶斯学派想到了将$H_{0}$时，$\theta$变成一个离散型随机变量，<strong>也就是说，我们考虑$\theta$的分布为一个离散型分布与连续型分布的组合</strong>。为此，我们需要在先验认识上，就得做出这样的考虑，即</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\theta) = p_{0}I_{\theta_{0}}(\theta)+p_{1}g(\theta)
\end{align*}</script><p>其中，$p_{0}$为为$\theta=\theta_{0}$时的概率值，$I_{\theta_{0}}(\theta)$为$\theta=\theta_{0}$（在本问题内$\theta_{0}=0.8$）时的概率密度，该函数为一个是示性函数，当且仅当$\theta=\theta_{0}$时取值为1，其余取0；$g(\theta)$为$\theta \neq \theta_{0}$（在本问题内$\theta_{0} \neq 0.8$）时的概率密度，且$p_{1}=1-p_{0}$（因为需要保证$p(\theta)$在参数空间下的积分为1）</p>
<p>上述的假设检验问题是我们在工作中最常遇到的一种问题，虽然这样的做法解决了问题，但是其实际含义缺乏解释性，因此贝叶斯假设检验在当前仍难以应用。</p>
]]></content>
      <categories>
        <category>Bayesian Data Analysis</category>
      </categories>
      <tags>
        <tag>Bayesian Data Analysis</tag>
      </tags>
  </entry>
  <entry>
    <title>Bayesian Data Analysis（三）：多参数模型</title>
    <url>/2021/11/29/20211129_Bayesian-Data-Analysis%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9A%E5%A4%9A%E5%8F%82%E6%95%B0%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="多参数模型简介"><a href="#多参数模型简介" class="headerlink" title="多参数模型简介"></a>多参数模型简介</h1><p>为了在数学上表示联合概率分布和边缘概率分布的思想，假如说我们的参数$\theta$包含两部分，即$\theta=(\theta_{1}, \theta_{2})^{T}$，如果在推断过程中，我对关心的是$\theta_{1}$， 那么$\theta_{2}$就会被看成是一个<strong>冗杂参数（nuisance parameter）</strong>，为简化起见，以正态分布为例</p>
<script type="math/tex; mode=display">
\begin{align*}
y \mid \mu, \sigma^{2} \sim N(\mu, \sigma^{2})
\end{align*}</script><p>假定$\mu, \sigma^{2}$均为未知参数，但我们目前推断仅关心$\mu$，那么$\sigma^{2}$就会被我们认定为是一个冗杂参数。</p>
<p>回到最初的表达式，如果说我们需要知道$\theta_{1}$的后验密度，那么我们可以表示为</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\theta_{1} \mid y) 
&= \int p(\theta_{1}, \theta_{2} \mid y) d\theta_{2}\\
&= \int p(\theta_{1} \mid y, \theta_{2})p(\theta_{2} \mid y) d\theta_{2}\\
\end{align*}</script><p>这个式子表明$\theta_{1}$的后验密度实际上是以$\theta_{2}$的后验分布加权的混合分布</p>
<p>同时我们还有</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\theta_{1}, \theta_{2} \mid y) 
&= \frac{p(\theta_{1}, \theta_{2}, y)}{p(y)}\\
&= \frac{p(y \mid \theta_{1}, \theta_{2})p(\theta_{1}, \theta_{2})}{p(y)}\\
&\propto p(y \mid \theta_{1}, \theta_{2})p(\theta_{1}, \theta_{2})\\
\end{align*}</script><p>可以得到</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\theta_{1} \mid y) 
&\propto \int p(y \mid \theta_{1}, \theta_{2})p(\theta_{1}, \theta_{2}) d\theta_{2}
\end{align*}</script><p>多参数模型部分总体还是比较难的，以了解思想为主</p>
<h1 id="在无信息先验分布下的正态数据"><a href="#在无信息先验分布下的正态数据" class="headerlink" title="在无信息先验分布下的正态数据"></a>在无信息先验分布下的正态数据</h1><h2 id="联合先验分布"><a href="#联合先验分布" class="headerlink" title="联合先验分布"></a>联合先验分布</h2><p>在$\mu, \sigma^{2}$均为未知参数的情况下，利用位置参数和尺度参数，我们可以知道$p(\mu)\propto constant$和 $p(\sigma^{2})\propto \frac{1}{\sigma^{2}}$（等价于$p(\log \sigma) \propto 1$），那么我们可以得到$\mu, \sigma^{2}$的联合概率密度</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\mu, \sigma^{2}) 
&= p(\sigma^{2} \mid \mu)p(\mu)\\
&\propto p(\sigma^{2} \mid \mu)\\
&=\frac{1}{\sigma^{2}}\\
\end{align*}</script><h2 id="联合后验分布"><a href="#联合后验分布" class="headerlink" title="联合后验分布"></a>联合后验分布</h2><p>在这个不恰当的先验分布情形下，仿照前文的推导，设观测数据为$y=\{y_{1}, \cdots, y_{n}\}$，利用最大似然法可得</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\mu, \sigma^{2}\mid y)
&\propto \prod_{i=1}^{n} p(y_{i} \mid \mu, \sigma^{2})p(\mu, \sigma^{2})\\
&\propto \frac{1}{\sigma^{2}}\prod_{i=1}^{n} \frac{1}{\sigma}e^{-\frac{(y_{i}-\mu)^{2}}{2\sigma^{2}}}\\
&=\frac{1}{\sigma^{n+2}}e^{-\sum_{i=1}^{n} \frac{(y_{i}-\mu)^{2}}{2\sigma^{2}}}\\
&=\frac{1}{\sigma^{n+2}}e^{-\sum_{i=1}^{n} \frac{(y_{i}-\bar{y}+\bar{y}-\mu)^{2}}{2\sigma^{2}}}\\
&=\frac{1}{\sigma^{n+2}}e^{- \frac{1}{2\sigma^{2}}[n(\bar{y}-\mu)^{2}+\sum_{i=1}^{n}(y_{i}-\bar{y})^{2}]} \quad \mbox{（应用了$\sum (y_{i}-\bar{y})=0$）}\\
&=\frac{1}{\sigma^{n+2}}e^{- \frac{1}{2\sigma^{2}}[n(\bar{y}-\mu)^{2}+(n-1)s^{2}]}\\
\end{align*}</script><p>其中$s^{2}=\frac{1}{n-1}\sum_{i=1}^{n}(y_{i}-\bar{y})^{2}$</p>
<h2 id="参数边缘后验分布"><a href="#参数边缘后验分布" class="headerlink" title="参数边缘后验分布"></a>参数边缘后验分布</h2><h3 id="sigma-2-的后验分布"><a href="#sigma-2-的后验分布" class="headerlink" title="$\sigma^{2}$的后验分布"></a>$\sigma^{2}$的后验分布</h3><p>如果我们所关心的参数是$\sigma^{2}$，那么利用我们第一部分的内容，对于$\sigma^{2}$的后验分布我们有</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\sigma^{2} \mid y) 
& \propto \int p(\mu, \sigma^{2}\mid y) d\mu\\ 
& \propto \frac{1}{\sigma^{n+1}}e^{- \frac{1}{2\sigma^{2}}(n-1)s^{2}}\\ 
\end{align*}</script><p>这个分布也就是$I-\chi^{2}$分布，满足$p(\sigma^{2} \mid y) =I-\chi^{2}(n-1, s^{2})$</p>
<!-- 同时在此前附录提到过若方差已知的情况下，当$n \rightarrow \infty$时，$p(\mu \mid \sigma^{2}, y)=N(\bar{y}, \frac{\sigma^{2}}{n})$

在以上条件下，我们已经尝试建立起了一个联合后验分布表达式：
$$
\begin{align*}
p(\mu, \sigma^{2}\mid y) = p(\sigma^{2} \mid y) p(\mu \mid \sigma^{2}, y)
\end{align*}
$$ -->
<h3 id="mu-的后验分布"><a href="#mu-的后验分布" class="headerlink" title="$\mu$的后验分布"></a>$\mu$的后验分布</h3><p>进一步，求$\mu$的后验分布：</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\mu \mid y) 
&= \int_{0}^{\infty} p(\mu, \sigma^{2}\mid y) d \sigma^{2}\\
&\propto [1+ \frac{1}{(n-1)}\frac{(\bar{y}-\mu)^{2}}{s^{2}/n}]^{-\frac{n}{2}}
\end{align*}</script><p>这实际上就是$t_{n-1}(\bar{y}, \frac{s^{2}}{n})$的密度函数<br>也就是说，在$(\mu, \log \sigma)$的无信息先验分布下，$\mu$的后验分布是一个t分布</p>
<h1 id="在共轭先验分布下的正态数据"><a href="#在共轭先验分布下的正态数据" class="headerlink" title="在共轭先验分布下的正态数据"></a>在共轭先验分布下的正态数据</h1><h2 id="在共轭先验分布下的正态数据-1"><a href="#在共轭先验分布下的正态数据-1" class="headerlink" title="在共轭先验分布下的正态数据"></a>在共轭先验分布下的正态数据</h2><p>假定</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\mu \mid \sigma^{2}) &= N(\mu_{0}, \frac{\sigma^{2}}{\kappa_{0}})\\
p(\sigma^{2}) &= I-\chi^{2}(\nu_{0}, \sigma_{0}^{2}) \quad \mbox{（借助前文的知识可得）}\\
\end{align*}</script><p>那么联合先验分布可以表示为</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\mu, \sigma^{2}) 
&=p(\mu \mid \sigma^{2})p(\sigma^{2})\\
&\propto \sigma^{-1}(\sigma^{2})^{-(\frac{\nu_{0}}{2}+1)}e^{-\frac{1}{2\sigma^{2}}[\nu_{0}\sigma_{0}^{2}+\kappa_{0}(\mu_{0}-\mu)^{2}]}\\
&=N-I-\chi^{2}(\mu, \sigma^{2} \mid \mu_{0}, \frac{\sigma^{2}}{\kappa_{0}}; \nu_{0}, \sigma_{0}^{2})\\
\end{align*}</script><blockquote>
<p>注：</p>
<ol>
<li>$p(\mu, \sigma^{2}) =N-I-\chi^{2}(\mu, \sigma^{2} \mid \mu_{0}, \frac{\sigma^{2}}{\kappa_{0}}; \nu_{0}, \sigma_{0}^{2})$表示正态-逆卡方分布</li>
<li>正态-逆卡方分布可以拆成两个部分，即最开始假定的：$\sigma^{2} \sim I-\chi^{2}(\nu_{0}, \sigma_{0}^{2})$和$\mu \mid \sigma^{2} \sim N(\mu_{0}, \frac{\sigma^{2}}{\kappa_{0}})$</li>
</ol>
</blockquote>
<p>设观测数据为$y=\{y_{1}, \cdots, y_{n}\}$，利用最大似然法可得</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\mu, \sigma^{2}\mid y)
&\propto \prod_{i=1}^{n} p(y_{i} \mid \mu, \sigma^{2})p(\mu, \sigma^{2})\\
&\propto 
\sigma^{-1}(\sigma^{2})^{-(\frac{\nu_{0}}{2}+1)}e^{-\frac{1}{2\sigma^{2}}[\nu_{0}\sigma_{0}^{2}+\kappa_{0}(\mu_{0}-\mu)^{2}]}
\prod_{i=1}^{n} \frac{1}{\sigma}e^{-\frac{(y_{i}-\mu)^{2}}{2\sigma^{2}}}\\
&=
\sigma^{-(n+1)}(\sigma^{2})^{-(\frac{\nu_{0}}{2}+1)}e^{-\frac{1}{2\sigma^{2}}[\nu_{0}\sigma_{0}^{2}+\kappa_{0}(\mu_{0}-\mu)^{2}]}
e^{-\sum_{i=1}^{n} \frac{(y_{i}-\mu)^{2}}{2\sigma^{2}}}\\
&=
\sigma^{-(n+1)}(\sigma^{2})^{-(\frac{\nu_{0}}{2}+1)}e^{-\frac{1}{2\sigma^{2}}[\nu_{0}\sigma_{0}^{2}+\kappa_{0}(\mu_{0}-\mu)^{2}]}
e^{- \frac{1}{2\sigma^{2}}[n(\bar{y}-\mu)^{2}+(n-1)s^{2}]}\\
&=
\sigma^{-(n+1)}(\sigma^{2})^{-(\frac{\nu_{0}}{2}+1)}
e^{-\frac{1}{2\sigma^{2}}[\nu_{0}\sigma_{0}^{2}+\kappa_{0}(\mu_{0}-\mu)^{2}+n(\bar{y}-\mu)^{2}+(n-1)s^{2}]}\\
&=
\sigma^{-1}(\sigma^{2})^{-(\frac{\nu_{0}+n}{2}+1)}
e^{-\frac{1}{2\sigma^{2}}[\nu_{0}\sigma_{0}^{2}+(n-1)s^{2}+\frac{n\kappa_{0}(\bar{y}-\mu_{0})^{2}}{\kappa_{0}+n}+(\kappa_{0}+n)(\mu-\frac{\mu_{0}\kappa_{0}+n\bar{y}}{\kappa_{0}+n})^{2}]}\\
&=N-I-\chi^{2}(\mu, \sigma^{2} \mid \mu_{n}, \frac{\sigma^{2}}{\kappa_{n}}; \nu_{n}, \sigma_{n}^{2})\\
\end{align*}</script><p>其中</p>
<script type="math/tex; mode=display">
\begin{align*}
\mu_{n}&=\frac{\kappa_{0}}{\kappa_{0}+n}\mu_{0}+\frac{n}{\kappa_{0}+n}\bar{y}\\
\kappa_{n}&=\kappa_{0}+n\\
\nu{n}&=\nu_{0}+n\\
\nu_{n}\sigma_{n}^{2}&=\nu_{0}\sigma_{0}^{2}+(n-1)s^{2}+\frac{\kappa_{0}n}{\kappa_{0}+n}(\bar{y}-\mu_{0})^{2}\\
\sigma_{n}^{2}&=\frac{\nu_{0}\sigma_{0}^{2}+(n-1)s^{2}+\frac{\kappa_{0} n}{\kappa_{0}+n}(\bar{y}-\mu_{0})^{2}}{\nu_{0}+n}\\
\end{align*}</script><p>由上面的结果可以拆解为</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\mu \mid y, \sigma^{2}) &= N(\mu_{n}, \frac{\sigma^{2}}{\kappa_{n}})\\
p(\sigma^{2} \mid y) &= I-\chi^{2}(\nu_{n}, \sigma_{n}^{2}))\\
\end{align*}</script><p>进一步，$\mu$的边缘概率密度为</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\mu \mid y) 
&= \int p(\mu \mid y, \sigma^{2}) d\sigma^{2}\\
&= (1+\frac{\kappa_{n}(\mu-\mu_{n})^{2}}{\nu_{n}\sigma_{n}^{2}})^{-\frac{\nu_{n}+1}{2}}\\
&= t_{\nu_{n}}(\mu \mid \mu_{n}, \frac{\sigma_{n}^{2}}{\kappa_{n}})\\
\end{align*}</script><h2 id="多元选择模型"><a href="#多元选择模型" class="headerlink" title="多元选择模型"></a>多元选择模型</h2><p>总体密度满足</p>
<script type="math/tex; mode=display">
\begin{align*}
p(y \mid \theta) \propto \prod_{i=1}^{n}\theta_{i}^{y_{i}}
\end{align*}</script><p>其中</p>
<script type="math/tex; mode=display">
\begin{align*}
\sum_{i=1}^{n} \theta_{i} &= 1\\
\sum_{i=1}^{n} y_{i} &= n\\
\end{align*}</script><p>共轭先验分布为狄利克雷分布</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\theta \mid \alpha) \propto \prod_{i=1}^{n}\theta_{i}^{\alpha_{i}-1}
\end{align*}</script><p>其中</p>
<script type="math/tex; mode=display">
\begin{align*}
\sum_{i=1}^{n} \theta_{i} &= 1\\
\end{align*}</script><p>则后验分布满足</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\theta \mid y, \alpha) 
&\propto \prod_{i=1}^{n}\theta_{i}^{y_{i}+\alpha_{i}-1}\\
&=Dirichlet(\theta, y+\alpha)
\end{align*}</script>]]></content>
      <categories>
        <category>Bayesian Data Analysis</category>
      </categories>
      <tags>
        <tag>Bayesian Data Analysis</tag>
      </tags>
  </entry>
  <entry>
    <title>Bayesian Data Analysis（二）：单参数模型</title>
    <url>/2021/11/28/20211128_Bayesian-Data-Analysis%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E5%8D%95%E5%8F%82%E6%95%B0%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>从第二到第三章，主要简单介绍下贝叶斯数据分析中的单参数模型和多参数模型，这里主要涉及到的数学知识会多一点，偏理解的东西会少一些，主要是认为，我们需要通过不断的实操前一篇所说的三个步骤，来强化我们对贝叶斯数据分析的理解（尤其是共轭先验部分和附录部分，是强化练习的最好方式）。</p>
<h1 id="一个例子：女性出生率估计"><a href="#一个例子：女性出生率估计" class="headerlink" title="一个例子：女性出生率估计"></a>一个例子：女性出生率估计</h1><p>在两百年前的欧洲，绝大数人相信女性出生率小于0.5。目前通过大量欧洲人口中估计，这个值是0.485，同上一章约定的符号，我们把女性出生率设定为$\theta$，那么男女出生性别比可以表示为$\phi=\frac{1-\theta}{\theta}$。同时我们设定在$n$个被记录的出生样本中，有$y$个是女性，那么我们可以用一个二项分布来对该问题建模，也就是</p>
<script type="math/tex; mode=display">
\begin{align*}
p(y \mid \theta) = Bin(y \mid n, \theta) = 
\begin{pmatrix}
n\\
y
\end{pmatrix}
\theta^{y}(1-\theta)^{n-y}
\end{align*}</script><p>假设我们对出生率的实际分布情况并不了解，那么我们可以假设$\theta$在集合里取任意一个值都是可能的，即$\theta \sim U(0, 1)$，用概率密度表示为$p(\theta)=1 \quad \theta \in [0, 1]$。</p>
<p>应用第一篇中提到的贝叶斯法则</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\theta \mid y) 
&\propto p(\theta)p(y \mid \theta)\\
&\propto \theta^{y}(1-\theta)^{n-y}
\end{align*}</script><p>而这恰好是Beta分布的一种：$\theta \mid y \sim Beta(y+1, n-y+1)$</p>
<p>在1745年至1770年，共有241945名女孩和251527名男孩出生，现需要检验女孩的出生率是否小于0.5，即确定下面概率值的大小</p>
<script type="math/tex; mode=display">
Pr(\theta \geq 0.5 \mid y=241945, n=241945+251527)</script><p>如果明确表达$p(\theta \mid y)$，即</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\theta \mid y) = 
\frac{\begin{pmatrix}n\\y\end{pmatrix}\theta^{y}(1-\theta)^{n-y}}{p(y)}
\end{align*}</script><p>其中</p>
<script type="math/tex; mode=display">
\begin{align*}
p(y) 
&= \int_{0}^{1} \begin{pmatrix}n\\y\end{pmatrix}\theta^{y}(1-\theta)^{n-y}d\theta\\
&= \frac{1}{n+1}
\end{align*}</script><p>进而</p>
<script type="math/tex; mode=display">
\begin{align*}
Pr(\theta \geq 0.5 \mid y, n)
&= \int_{0.5}^{1}p(\theta \mid y) d\theta\\
&\approx 1.15 \times 10^{-42}
\end{align*}</script><p>因此”几乎可以”确定女性出生率低于0.5。</p>
<p>在得到后验分布的情况下，我们重新抽取一份出生记录，这个婴儿的性别为女性($\widetilde{y}=1$)的概率为</p>
<script type="math/tex; mode=display">
\begin{align*}
Pr(\widetilde{y}=1 \mid y)
&= \int_{0}^{1} Pr(\widetilde{y}=1 \mid y, n)p(\theta \mid y) d\theta\\
&= \int_{0}^{1} Pr(\widetilde{y}=1 \mid n)p(\theta \mid y) d\theta\\
&= \int_{0}^{1} \theta p(\theta \mid y) d\theta\\
&= \frac{y+1}{n+2}
\end{align*}</script><h1 id="信息先验分布"><a href="#信息先验分布" class="headerlink" title="信息先验分布"></a>信息先验分布</h1><h2 id="共轭先验分布"><a href="#共轭先验分布" class="headerlink" title="共轭先验分布"></a>共轭先验分布</h2><p>通过Beta分布的表达式，我们可以把区间$(0, 1)$的均匀分布看成是$Beta(1, 1)$。那么上面的例子则变得有意思起来。如果我们取先验分布为$\theta  \sim Beta(1, 1)$，在总体分布为$y \mid \theta \sim Bin(n, \theta)$的情况下，后验分布也是一类Beta分布，即$\theta \mid y \sim Beta(y+1, n-y+1)$。这也就意味着，<strong>对于某一些总体分布，如果我们能够取适当的先验分布，那么我们的后验分布和先验分布会在同一类分布簇</strong>，我们只需要稍加调整参数值就可以非常方便的去进行后验分布的计算。</p>
<h3 id="共轭先验分布的定义"><a href="#共轭先验分布的定义" class="headerlink" title="共轭先验分布的定义"></a>共轭先验分布的定义</h3><p>设$\theta$为总体分布中的参数，其抽样分布属于$\mathcal{F}$分布簇，$p(\theta)$是$\theta$的先验密度函数，分布属于$\mathcal{P}$分布簇，若抽样后计算的后验密度函数和$p(\theta)$处于同一分布簇中，那么我们认为$\mathcal{P}$和$\mathcal{F}$是共轭的</p>
<blockquote>
<ol>
<li>需要强调，共轭先验分布是<strong>针对某一分布中的参数而言的</strong>，如正态分布中的均值和方差参数，泊松分布的均值参数等。</li>
<li>在现实生活中使用共轭先验分布的机会相对较小，实际上大多情况都是用的是非共轭先验分布</li>
</ol>
</blockquote>
<h3 id="共轭先验分布的优缺点"><a href="#共轭先验分布的优缺点" class="headerlink" title="共轭先验分布的优缺点"></a>共轭先验分布的优缺点</h3><p>优点：</p>
<ol>
<li>计算方便</li>
<li>后验分布的一些参数可以得到很好的解释</li>
</ol>
<p>缺点：</p>
<ol>
<li>先验分布的选择需要符合现实情况，错误选择先验分布，可能会掩盖后验分布的实际情况</li>
</ol>
<h3 id="常用共轭先验分布"><a href="#常用共轭先验分布" class="headerlink" title="常用共轭先验分布"></a>常用共轭先验分布</h3><p>列举一些常用的共轭先验分布，具体证明放在<a href="#attatch2">附录2</a>，如感兴趣可以阅读</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>总体分布</th>
<th>参数</th>
<th>共轭先验分布</th>
</tr>
</thead>
<tbody>
<tr>
<td>二项分布</td>
<td>抽取概率</td>
<td>Beta分布</td>
</tr>
<tr>
<td>泊松分布</td>
<td>均值</td>
<td>Gamma分布</td>
</tr>
<tr>
<td>指数分布</td>
<td>均值（均值倒数）</td>
<td>Gamma分布</td>
</tr>
<tr>
<td>正态分布（方差已知）</td>
<td>均值</td>
<td>正态分布</td>
</tr>
<tr>
<td>正态分布（均值已知）</td>
<td>方差</td>
<td>倒Gamma分布</td>
</tr>
</tbody>
</table>
</div>
<h3 id="频率学派与贝叶斯学派的差异（点估计）"><a href="#频率学派与贝叶斯学派的差异（点估计）" class="headerlink" title="频率学派与贝叶斯学派的差异（点估计）"></a>频率学派与贝叶斯学派的差异（点估计）</h3><p>在贝叶斯学派观点下，以正态分布（方差已知）的情况为例，最终我们后验分布的参数满足</p>
<script type="math/tex; mode=display">
\begin{align*}
\mu_{n} 
&= \frac{\frac{1}{\sigma_{0}^{2}}\mu_{0}+\frac{n}{\sigma^{2}}\bar{y}}{\frac{1}{\sigma_{0}^{2}}+\frac{n}{\sigma^{2}}}\\
\frac{1}{\sigma_{n}^{2}} 
&= \frac{1}{\sigma_{0}^{2}} + \frac{n}{\sigma^{2}}
\end{align*}</script><p>如果我们令$\gamma=\frac{\frac{1}{\sigma_{0}^{2}}}{\frac{1}{\sigma_{0}^{2}}+\frac{n}{\sigma^{2}}}$，稍加变换可得</p>
<script type="math/tex; mode=display">
\begin{align*}
\mu_{n} 
&= \gamma \mu_{0}+(1-\gamma)\bar{y}\\
\frac{1}{\sigma_{n}^{2}} 
&= \frac{1}{\sigma_{0}^{2}} + \frac{1}{\sigma^{2}/n}=\frac{1}{\sigma_{0}^{2}} + \frac{1}{s^{2}}
\end{align*}</script><p>也就是说，<strong>后验分布的均值是先验分布均值与样本均值的加权和，而后验分布的方差的倒数是先验分布方差倒数与样本方差倒数的和</strong>。</p>
<p>而在频率学派观点下，我们认为<strong>对总体的最好估计就是样本的估计</strong>，即总体均值的无偏估计为样本均值，总体方差的估计为样本方差的期望</p>
<h1 id="无信息先验分布"><a href="#无信息先验分布" class="headerlink" title="无信息先验分布"></a>无信息先验分布</h1><h2 id="Jeffrey不变性法则"><a href="#Jeffrey不变性法则" class="headerlink" title="Jeffrey不变性法则"></a>Jeffrey不变性法则</h2><p>设$\theta$的一个单射是$\phi=h(\theta)$，则有</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\phi) = p(\theta) \vert \frac{d\theta}{d\phi} \vert = p(\theta) \vert h^{'}(\theta) \vert^{-1}
\end{align*}</script><p>Jeffrey无偏法则试图找到一个无信息先验密度类似于$p(\theta) \propto [J(\theta)]^{\frac{1}{2}}$，这个分布不会随着$\theta$的变化发生变化，其中$J(\theta)$是$\theta$的<strong>Fisher信息矩阵</strong>：</p>
<script type="math/tex; mode=display">
\begin{align*}
J(\theta) 
&= E\{(\frac{d \log p(y \mid \theta)}{d\theta})^{2} \mid \theta\}\\
&= -E\{\frac{d^{2} \log p(y \mid \theta)}{d\theta^{2}} \mid \theta\}
\end{align*}</script><p>关于$J(\theta)$的先验分布不变性的证明，详见<a href="#attatch3">附录3</a></p>
<h2 id="关键数量法"><a href="#关键数量法" class="headerlink" title="关键数量法"></a>关键数量法</h2><h3 id="位置参数"><a href="#位置参数" class="headerlink" title="位置参数"></a>位置参数</h3><p>假设$y$的密度$p(y-\theta \mid \theta)$不受$\theta$和$y$的影响，我们暂且假定为$f(u)$，其中$u=y-\theta$，那么$y-\theta$称为<strong>不变数量</strong>，$\theta$被称为<strong>位置参数</strong>。在这种情形下，针对$\theta$，我们利用$f(u)$去得到后验分布$p(y-\theta \mid y)$，此时$y-\theta$依旧是不变的。在这种条件下，应用贝叶斯法则可得$p(y-\theta \mid y)\propto p(\theta)p(y-\theta \mid \theta)$，这也就暗示着$\theta$的无信息先验分布是一个均匀分布，且在$\mathbb{R}$上满足$p(\theta)\propto constant$</p>
<h3 id="尺度参数"><a href="#尺度参数" class="headerlink" title="尺度参数"></a>尺度参数</h3><p>假设$y$的密度$p(\frac{y}{\theta} \mid \theta)$不受$\theta$和$y$的影响，我们暂且假定为$g(u)$，其中$u=\frac{y}{\theta}$，那么$\frac{y}{\theta}$称为<strong>不变数量</strong>，$\theta$被称为<strong>尺度参数</strong>。在这种情形下，针对$\theta$，我们利用$g(u)$去得到后验分布$p(\frac{y}{\theta} \mid y)$，此时$\frac{y}{\theta}$依旧是不变的。在这种条件下，通过变量代换，给定$\theta$时$y$的条件分布满足</p>
<script type="math/tex; mode=display">
\begin{align*}
p(y \mid \theta) = \frac{1}{\theta}p(u \mid \theta)
\end{align*}</script><p>后验分布满足</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\theta \mid y) = \frac{y}{\theta^{2}}p(u \mid \theta)
\end{align*}</script><p>让$p(\theta \mid y)$和$p(y \mid \theta)$都等于$g(u)$，那么可得$p(\theta \mid y)=\frac{y}{\theta}p(y \mid \theta)$，因此这个参考的先验分布$p(\theta)\propto \frac{1}{\theta}$（或写成$p(\theta^{2})\propto \frac{1}{\theta^{2}}$/$p(\log \theta)\propto 1$）</p>
<h2 id="无信息先验分布-1"><a href="#无信息先验分布-1" class="headerlink" title="无信息先验分布"></a>无信息先验分布</h2><ol>
<li><strong>寻找一个总是模糊的先验分布似乎是错误的</strong>。比如似然估计在一个特定问题中占据着主要地位，那么使用一个平滑的无信息先验分布就是一种误导行为</li>
<li>对于大量的问题，使用哪一种模糊的先验分布没有一个明确的答案，在参数化过程中密度是平滑的还是均匀的只可能是一种情况。比如正态分布的方差，我们假定$p(\sigma^{2})\propto \frac{1}{\sigma^{2}}$似乎是合理的，但如果我们定义$\phi=\log \sigma^{2}$则有：</li>
</ol>
<script type="math/tex; mode=display">
\begin{align*}
p(\phi) 
&= p(\theta) \vert \frac{d\theta}{d\phi} \vert\\
&\propto \frac{1}{\sigma^{2}}\sigma^{2}\\
&=1\\
\end{align*}</script><p>这也就是说在$\phi=\log \sigma^{2}$，密度是均匀的，这看起来似乎并不是很合理</p>
<ol>
<li>当我们在对一组竞争性模型平均化石会带来很多困难</li>
</ol>
<h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><div id="attatch1"></div>

<h2 id="常见分布"><a href="#常见分布" class="headerlink" title="常见分布"></a>常见分布</h2><h3 id="Binormal-Distribution"><a href="#Binormal-Distribution" class="headerlink" title="Binormal Distribution"></a>Binormal Distribution</h3><p>概率函数</p>
<script type="math/tex; mode=display">
\begin{align*}
p(y \mid \theta) =  
\begin{pmatrix}
n\\
y
\end{pmatrix}
\theta^{y}(1-\theta)^{n-y}
\end{align*}</script><p>期望</p>
<script type="math/tex; mode=display">
\begin{align*}
E(\theta \mid y) 
&= \sum_{y=1}^{n} yp(y \mid \theta)\\
&= n\theta \sum_{y=1}^{n-1} \begin{pmatrix}n-1\\ y-1 \end{pmatrix} \theta^{y-1}(1-\theta)^{(n-1)-(y-1)} \\
&= n\theta
\end{align*}</script><p>方差</p>
<script type="math/tex; mode=display">
\begin{align*}
var(\theta) 
&= E(\theta \mid y^{2}) - (E(\theta \mid y))^{2}\\
&= \sum_{y=1}^{n} y^{2}p(y \mid \theta) - (E(\theta \mid y))^{2}\\
&= \sum_{y=1}^{n} y(y-1) p(y \mid \theta) + E(\theta \mid y) - (E(\theta \mid y))^{2}\\
&= n(n-1)\theta^{2}\sum_{y=1}^{n-2} \begin{pmatrix}n-2\\ y-2 \end{pmatrix} \theta^{y-2}(1-\theta)^{(n-2)-(y-2)} + E(\theta \mid y) - (E(\theta \mid y))^{2}\\
&= n(n-1)\theta^{2} + E(\theta \mid y) - (E(\theta \mid y))^{2}\\
&= n\theta(1-\theta)
\end{align*}</script><h3 id="Poisson-Distribution"><a href="#Poisson-Distribution" class="headerlink" title="Poisson Distribution"></a>Poisson Distribution</h3><p>概率函数</p>
<script type="math/tex; mode=display">
\begin{align*}
p(y \mid \theta) =  
\frac{\theta^{y}}{y!}e^{-\theta}
\end{align*}</script><p>期望</p>
<script type="math/tex; mode=display">
\begin{align*}
E(\theta \mid y) 
&= \sum_{y=1}^{\infty} yp(y \mid \theta)\\
&= \sum_{y=1}^{\infty} y\frac{\theta^{y}}{y!}e^{-\theta}\\
&= \theta e^{-\theta} \sum_{y=1}^{\infty} \frac{\theta^{y-1}}{(y-1)!}\\
&= \theta e^{-\theta} e^{\theta} \quad \mbox{(幂级数求和)}\\
&= \theta
\end{align*}</script><p>方差</p>
<script type="math/tex; mode=display">
\begin{align*}
var(\theta) 
&= E(\theta \mid y^{2}) - (E(\theta \mid y))^{2} \quad \mbox{(同二项分布做法)}\\
&= \theta
\end{align*}</script><h3 id="Chi-Square-Distribution"><a href="#Chi-Square-Distribution" class="headerlink" title="Chi-Square Distribution"></a>Chi-Square Distribution</h3><p>若n个随机变量$\xi{1}, \cdots,\xi{\nu}$<strong>独立同分布于标准正态分布</strong>，则$Z=\sum_{i=1}^{n}\xi_{i}$服从一个新的分布，即$\chi^{2}$分布，且满足$Z \sim \chi_{\nu}^{2}$（或称为$Z \sim \chi^{2}(\nu)$），其中$\nu$为自由度，$\chi^{2}$分布也等价于$Gamma(\frac{\nu}{2}, \frac{1}{2})$</p>
<p>对于$\chi^{2}$分布，其概率函数为</p>
<script type="math/tex; mode=display">
\begin{align*}
p(y \mid \nu) 
&=  \chi_{\nu}^{2}(y)\\
&=\frac{2^{-\frac{\nu}{2}}}{\Gamma(\frac{\nu}{2})}y^{\frac{\nu}{2}-1}e^{-\frac{y}{2}}
\end{align*}</script><p>期望</p>
<script type="math/tex; mode=display">
\begin{align*}
E(\nu \mid y) 
&= \int y \frac{2^{-\frac{\nu}{2}}}{\Gamma(\frac{\nu}{2})}y^{\frac{\nu}{2}-1}e^{-\frac{y}{2}} dy\\
&= \nu
\end{align*}</script><p>方差</p>
<script type="math/tex; mode=display">
\begin{align*}
var(\nu) 
&= E(\nu \mid y^{2}) - (E(\nu \mid y))^{2}\\
&= 2\nu\\
\end{align*}</script><p>P.S.  更常用的方法是利用标准正态分布及期望算子线性性的性质进行简化计算，例如</p>
<p>期望</p>
<script type="math/tex; mode=display">
\begin{align*}
E(\nu \mid y) 
&= E(\sum_{i=1}^{\nu}y_{i}^{2})\\
&= \sum_{i=1}^{\nu}E(y_{i}^{2})\\
&= \sum_{i=1}^{\nu}[D(y_{i})+(E(y_{i})^{2})] \quad \mbox{（应用方差计算公式）}\\
&= \sum_{i=1}^{\nu}(1+0)\\
&=\nu
\end{align*}</script><p>方差可同理计算</p>
<h3 id="Exponential-Distribution"><a href="#Exponential-Distribution" class="headerlink" title="Exponential Distribution"></a>Exponential Distribution</h3><p>概率函数</p>
<script type="math/tex; mode=display">
\begin{align*}
p(y \mid \theta) =  
\theta e^{-\theta y} \quad y \gt 0
\end{align*}</script><p>期望</p>
<script type="math/tex; mode=display">
\begin{align*}
E(\theta \mid y) 
&= \int y \theta e^{-\theta y} dy\\
&= \frac{1}{\theta}
\end{align*}</script><p>方差</p>
<script type="math/tex; mode=display">
\begin{align*}
var(\theta) 
&= E(\theta \mid y^{2}) - (E(\theta \mid y))^{2}\\
&= \frac{1}{\theta^{2}}\\
\end{align*}</script><h3 id="Normal-Distribution"><a href="#Normal-Distribution" class="headerlink" title="Normal Distribution"></a>Normal Distribution</h3><p>概率函数</p>
<script type="math/tex; mode=display">
\begin{align*}
p(y \mid \mu, \sigma) =  
\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(y-\mu)^{2}}{2\sigma^{2}}}
\end{align*}</script><p>期望</p>
<p>利用标准正态分布为奇函数的性质以及线性期望的性质</p>
<script type="math/tex; mode=display">
\begin{align*}
E(\mu, \sigma \mid y)
&= \mu
\end{align*}</script><p>方差同理</p>
<script type="math/tex; mode=display">
\begin{align*}
var(\mu, \sigma) 
&= E(\mu, \sigma \mid y^{2}) - (E(\mu, \sigma\mid y))^{2}\\
&= \sigma^{2}
\end{align*}</script><h3 id="Uniform-Distribution"><a href="#Uniform-Distribution" class="headerlink" title="Uniform Distribution"></a>Uniform Distribution</h3><script type="math/tex; mode=display">
\begin{align*}
p(y \mid a, b) =  
\frac{1}{b-a}
\end{align*}</script><p>期望</p>
<script type="math/tex; mode=display">
\begin{align*}
E(a, b \mid y) 
&= \int y p(y \mid a, b) dy\\
&= \frac{a+b}{2}
\end{align*}</script><p>方差</p>
<script type="math/tex; mode=display">
\begin{align*}
var(a, b) 
&= E(a, b \mid y^{2}) - (E(a, b \mid y))^{2}\\
&= \frac{(b-a)^{2}}{12}\\
\end{align*}</script><h3 id="Gamma-Distribution"><a href="#Gamma-Distribution" class="headerlink" title="Gamma Distribution"></a>Gamma Distribution</h3><p>Gamma函数</p>
<script type="math/tex; mode=display">
\begin{align*}
\Gamma(\alpha) = \int_{0}^{\infty} y^{\alpha-1}e^{-y}dy
\end{align*}</script><p>Gamma函数的性质：</p>
<ol>
<li>余元公式：$\Gamma(1-\alpha)\Gamma(\alpha)=\frac{\pi}{\sin \pi x}$</li>
<li>$\Gamma(1)=1, \Gamma(\frac{1}{2})=\sqrt{\pi}$</li>
<li>$\Gamma(\alpha+1)=\alpha\Gamma(\alpha)$</li>
</ol>
<p>概率函数</p>
<script type="math/tex; mode=display">
\begin{align*}
p(y \mid \lambda, \alpha) =  
\frac{\lambda^{\alpha}}{\Gamma(\alpha)}y^{\alpha-1}e^{-\lambda y}
\end{align*}</script><p>期望</p>
<script type="math/tex; mode=display">
\begin{align*}
E(\lambda, \alpha \mid y) 
&= \frac{\lambda^{\alpha}}{\Gamma(\alpha)} \int_{0}^{\infty} y^{\alpha}e^{-\lambda y}dy\\
&= \frac{\lambda^{\alpha}}{\Gamma(\alpha)} \frac{1}{\lambda^{\alpha}} \int_{0}^{\infty} (\lambda y)^{\alpha}e^{-\lambda y}d(\lambda y)\\
&= \frac{\lambda^{\alpha}}{\Gamma(\alpha)} \frac{\Gamma(\alpha+1)}{\lambda^{\alpha+1}} \\
&= \frac{\alpha}{\lambda}
\end{align*}</script><p>方差</p>
<script type="math/tex; mode=display">
\begin{align*}
var(\lambda, \alpha) 
&= E(\lambda, \alpha \mid y^{2}) - (E(\lambda, \alpha \mid y))^{2}\\
&= \frac{\alpha}{\lambda^{2}}
\end{align*}</script><h3 id="Beta-Distribution"><a href="#Beta-Distribution" class="headerlink" title="Beta Distribution"></a>Beta Distribution</h3><p>Beta函数</p>
<script type="math/tex; mode=display">
\begin{align*}
Beta(a, b) = \int_{0}^{1} y^{\alpha-1}(1-y)^{b-1}dy
\end{align*}</script><p>Beta函数的性质：</p>
<ol>
<li>$Beta(a, b)=Beta(b, a)$</li>
<li>$Beta(a, b)=\frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)}$</li>
</ol>
<p>概率函数</p>
<script type="math/tex; mode=display">
\begin{align*}
p(y \mid a, b) =  
\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}y^{a-1}(1-y)^{b-1} \quad y\in (0,1)
\end{align*}</script><p>期望</p>
<script type="math/tex; mode=display">
\begin{align*}
E(a, b \mid y) 
&= \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} \int_{0}^{1} y^{\alpha}(1-y)^{b-1}dy\\
&= \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} \frac{\Gamma(a+1)\Gamma(b)}{\Gamma(a+b+1)}\\
&=\frac{a}{a+b}
\end{align*}</script><p>方差</p>
<script type="math/tex; mode=display">
\begin{align*}
var(a, b) 
&= E(a, b \mid y^{2}) - (E(a, b \mid y))^{2}\\
&= \frac{ab}{(a+b)^{2}(a+b+1)}
\end{align*}</script><h3 id="Dirichlet-Distribution"><a href="#Dirichlet-Distribution" class="headerlink" title="Dirichlet Distribution"></a>Dirichlet Distribution</h3><p>狄利克雷分布（也叫多元Beta分布）是一类在实数域以正单纯形（standard simplex）为支撑集（support）的高维连续概率分布，是Beta分布在高维情形的推广。</p>
<p>概率函数</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\theta \mid \alpha_{1}, \cdots, \alpha_{n}) = \frac{\Gamma(\sum_{i=1}^{n}\alpha_{i})}{\prod_{i=1}^{n}\Gamma(\alpha_{i})}\theta_{i}^{\alpha_{i}-1}
\end{align*}</script><p>期望</p>
<script type="math/tex; mode=display">
\begin{align*}
E(\theta_{i}) 
&= \frac{\alpha_{i}}{\alpha_{0}}
\end{align*}</script><p>方差</p>
<script type="math/tex; mode=display">
\begin{align*}
var(\theta_{i}) 
&= \frac{\alpha_{i}(\alpha_{0}-\alpha_{i})}{\alpha_{0}^{2}(\alpha_{0}+1)}
\end{align*}</script><p>协方差</p>
<script type="math/tex; mode=display">
\begin{align*}
cov(\theta_{i}, \theta_{j}) 
&= -\frac{\alpha_{i}\alpha_{j}}{\alpha_{0}^{2}(\alpha_{0}+1)}
\end{align*}</script><div id="attatch2"></div>

<h2 id="共轭先验分布的证明"><a href="#共轭先验分布的证明" class="headerlink" title="共轭先验分布的证明"></a>共轭先验分布的证明</h2><h3 id="Binormal-Distribution-1"><a href="#Binormal-Distribution-1" class="headerlink" title="Binormal Distribution"></a>Binormal Distribution</h3><p>正态分布相对比较简单，在此不考虑多观测值的情况直接证明<br>总体分布满足</p>
<script type="math/tex; mode=display">
\begin{align*}
p(y \mid \theta) \propto \theta^{y}(1-\theta)^{n-y}
\end{align*}</script><p>取先验分布$p(\theta)$为$Beta(\alpha, \beta)$</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\theta) \propto \theta^{\alpha-1}(1-\theta)^{\beta-1}
\end{align*}</script><p>那么后验分布$p(\theta \mid y)$满足</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\theta \mid y) 
&\propto \theta^{y}(1-\theta)^{n-y}\theta^{\alpha-1}(1-\theta)^{\beta-1}\\
&=\theta^{y+\alpha-1}(1-\theta)^{n-y+\beta-1}\\
&=Beta(\alpha+y, n-y+\beta)
\end{align*}</script><h3 id="Poisson-Distribution-1"><a href="#Poisson-Distribution-1" class="headerlink" title="Poisson Distribution"></a>Poisson Distribution</h3><p>总体分布满足</p>
<script type="math/tex; mode=display">
\begin{align*}
p(y_{i} \mid \theta) =  
\frac{\theta^{y_{i}}}{y_{i}!}e^{-\theta}
\end{align*}</script><p>设观测数据为$y=\{y_{1}, \cdots, y_{n}\}$，利用最大似然法可得</p>
<script type="math/tex; mode=display">
\begin{align*}
p(y \mid \theta) 
&=  \prod_{i=1}^{n} \frac{\theta^{y_{i}}}{y_{i}!}e^{-\theta}\\
&=   \frac{\theta^{\sum_{i=1}^{n} y_{i}}}{\prod_{i=1}^{n}y_{i}!}e^{-n\theta}\\
&\propto \theta^{t}e^{-n\theta}
\end{align*}</script><p>其中$t=\sum_{i=1}^{n} y_{i}$</p>
<p>取先验分布$p(\theta)$为$Gamma(\alpha, \lambda)$</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\theta \mid \lambda, \alpha) 
&=  \frac{\lambda^{\alpha}}{\Gamma(\alpha)}\theta^{\alpha-1}e^{-\lambda \theta}\\
&\propto \theta^{\alpha-1}e^{-\lambda \theta}
\end{align*}</script><p>那么后验分布$p(\theta \mid y)$满足</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\theta \mid y) 
&\propto \theta^{t}e^{-n\theta} \theta^{\alpha-1}e^{-\lambda \theta}\\
&=\theta^{t+\alpha-1}e^{-(\lambda+n)\theta}\\
&\propto Gamma(t+\alpha, \lambda+n)
\end{align*}</script><h3 id="Exponential-Distribution-1"><a href="#Exponential-Distribution-1" class="headerlink" title="Exponential Distribution"></a>Exponential Distribution</h3><p>总体分布满足</p>
<script type="math/tex; mode=display">
\begin{align*}
p(y_{i} \mid \theta) =  
\theta e^{-\theta y_{i}} \quad y_{i} \gt 0
\end{align*}</script><p>设观测数据为$y=\{y_{1}, \cdots, y_{n}\}$，利用最大似然法可得</p>
<script type="math/tex; mode=display">
\begin{align*}
p(y \mid \theta) 
&=  \prod_{i=1}^{n} \theta e^{-\theta y_{i}}\\
&=   \theta^{n} e^{-\theta \sum_{i=1}^{n} y_{i}}\\
&\propto \theta^{n}e^{-\theta t}
\end{align*}</script><p>其中$t=\sum_{i=1}^{n} y_{i}$</p>
<p>取先验分布$p(\theta)$为$Gamma(\alpha, \lambda)$</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\theta \mid \lambda, \alpha) 
&=  \frac{\lambda^{\alpha}}{\Gamma(\alpha)}\theta^{\alpha-1}e^{-\lambda \theta}\\
&\propto \theta^{\alpha-1}e^{-\lambda \theta}
\end{align*}</script><p>那么后验分布$p(\theta \mid y)$满足</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\theta \mid y) 
&\propto\theta^{n}e^{-\theta t} \theta^{\alpha-1}e^{-\lambda \theta}\\
&=\theta^{n+\alpha-1}e^{-(\lambda+t)\theta}\\
&\propto Gamma(n+\alpha, \lambda+t)
\end{align*}</script><h3 id="Normal-Distribution-with-Known-Variance"><a href="#Normal-Distribution-with-Known-Variance" class="headerlink" title="Normal Distribution with Known Variance"></a>Normal Distribution with Known Variance</h3><p>总体分布满足</p>
<script type="math/tex; mode=display">
\begin{align*}
p(y_{i} \mid \theta) =  
\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(y_{i}-\theta)^{2}}{2\sigma^{2}}}
\end{align*}</script><p>设观测数据为$y=\{y_{1}, \cdots, y_{n}\}$，利用最大似然法可得</p>
<script type="math/tex; mode=display">
\begin{align*}
p(y \mid \theta) 
&=  \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(y_{i}-\theta)^{2}}{2\sigma^{2}}}\\
& \propto  e^{-\frac{\sum_{i=1}^{n} (y_{i}-\theta)^{2}}{2\sigma^{2}}}\\
\end{align*}</script><p>取先验分布$p(\theta)$为$N(\mu_{0}, \sigma_{0})$</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\theta \mid \mu_{0}, \sigma_{0}) 
& \propto  e^{-\frac{(\theta-\mu_{0})^{2}}{2\sigma_{0}^{2}}}\\
\end{align*}</script><p>那么后验分布$p(\theta \mid y)$满足</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\theta \mid y) 
&\propto 
e^{-\frac{1}{2\sigma^{2}}\sum_{i=1}^{n} (y_{i}-\theta)^{2}} 
e^{-\frac{1}{2\sigma_{0}^{2}}(\theta-\mu_{0})^{2}}\\
&\propto 
e^{-\frac{1}{2\sigma^{2}}n(\theta^{2}-2\bar{y})} 
e^{-\frac{1}{2\sigma_{0}^{2}}(\theta^{2}-2\mu_{0}\theta)}\\
\end{align*}</script><p>令</p>
<script type="math/tex; mode=display">
\begin{align*}
\mu_{n} 
&= \frac{\frac{1}{\sigma_{0}^{2}}\mu_{0}+\frac{n}{\sigma^{2}}\bar{y}}{\frac{1}{\sigma_{0}^{2}}+\frac{n}{\sigma^{2}}}\\
\frac{1}{\sigma_{n}^{2}} 
&= \frac{1}{\sigma_{0}^{2}} + \frac{n}{\sigma^{2}}
\end{align*}</script><p>上式可以改写成</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\theta \mid y) 
&\propto 
e^{-\frac{1}{2\sigma_{n}^{2}}(\theta-\mu_{n})^{2}}\\
\end{align*}</script><p>特别的，当$n \rightarrow \infty$时，由上面的结果可以导出，$p(\theta \mid y)=N(\bar{y}, \frac{\sigma^{2}}{n})$</p>
<h3 id="Normal-Distribution-with-Known-Mean"><a href="#Normal-Distribution-with-Known-Mean" class="headerlink" title="Normal Distribution with Known Mean"></a>Normal Distribution with Known Mean</h3><p>总体分布满足</p>
<script type="math/tex; mode=display">
\begin{align*}
p(y_{i} \mid \theta) =  
\frac{1}{\sqrt{2\pi \theta}}e^{-\frac{(y_{i}-\mu)^{2}}{2\theta}}
\end{align*}</script><p>设观测数据为$y=\{y_{1}, \cdots, y_{n}\}$，利用最大似然法可得</p>
<script type="math/tex; mode=display">
\begin{align*}
p(y \mid \theta) 
&=  \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi\theta}}e^{-\frac{(y_{i}-\mu)^{2}}{2\theta^{2}}}\\
& \propto  \theta^{-\frac{n}{2}}e^{-\frac{t}{2\theta}}\\
\end{align*}</script><p>其中$t=\sum_{i=1}^{n} (y_{i}-\mu)^{2}$</p>
<p>取先验分布$p(\theta)$为倒Gamma分布$I-Gamma(\alpha, \lambda)$</p>
<blockquote>
<p>$p(y \mid \alpha, \lambda) = \frac{\lambda^{\alpha}}{\Gamma(\alpha)}y^{-\alpha-1}e^{-\frac{\lambda}{y}}$<br>$E(\alpha, \lambda \mid y) = \frac{\Gamma(\alpha-1)}{\Gamma(\alpha)}\lambda$<br>$var(\alpha, \lambda) = \frac{\lambda^{2}}{(\alpha-1)^{2}(\alpha-2)}$</p>
</blockquote>
<script type="math/tex; mode=display">
\begin{align*}
p(\theta) 
& \propto  (\theta)^{-\alpha-1}e^{-\frac{\lambda}{\theta}}\\
\end{align*}</script><p>那么后验分布$p(\theta \mid y)$满足</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\theta \mid y) 
&\propto 
\theta^{-\frac{n}{2}}e^{-\frac{t}{2\theta}}
\theta^{-\alpha-1}e^{-\frac{\lambda}{\theta}}\\
&= \theta^{-\frac{n}{2}-\alpha-1}e^{-\frac{\lambda}{\theta}-\frac{t}{2\theta}}\\
\end{align*}</script><p>即同样为倒Gamma分布</p>
<p><div id="attatch3"></div></p>
<h2 id="Jeffrey先验分布不变性的证明"><a href="#Jeffrey先验分布不变性的证明" class="headerlink" title="Jeffrey先验分布不变性的证明"></a>Jeffrey先验分布不变性的证明</h2><p>考虑单参数情形</p>
<p>证明1:<br>验证在$\theta=h^{-1}(\phi)$情形下的J(\phi)：</p>
<script type="math/tex; mode=display">
\begin{align*}
J(\phi) 
&= -E\{\frac{d^{2} \log p(y \mid \phi)}{d\phi^{2}} \mid \phi\}\\
&= -E\{\frac{d^{2} \log p(y \mid \theta=h^{-1}(\phi))}{d\theta^{2}} \vert \frac{d\theta}{d\phi} \vert^{2} \} \quad \mbox{（应用}p(\phi) = p(\theta) \vert \frac{d\theta}{d\phi} \vert = p(\theta) \vert h^{'}(\theta) \vert^{-1} \mbox{）}\\
&= J(\theta) \vert \frac{d\theta}{d\phi} \vert^{2}
\end{align*}</script><p>说明$J(\theta)$同样满足$p(\phi) = p(\theta) \vert \frac{d\theta}{d\phi} \vert = p(\theta) \vert h^{‘}(\theta) \vert^{-1}$</p>
<p>证明2:</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\phi) 
&= p(\theta) \vert \frac{d\theta}{d\phi} \vert\\
&\propto \sqrt{J(\theta) \vert \frac{d\theta}{d\phi} \vert^{2}}\\
&= \sqrt{E\{(\frac{d \log p(y \mid \theta)}{d\theta})^{2} \mid \theta\} \vert \frac{d\theta}{d\phi} \vert^{2}}\\
&= \sqrt{E\{(\frac{d \log p(y \mid \theta)}{d\theta}\frac{d\theta}{d\phi})^{2} \mid \theta\}}\\
&= \sqrt{J(\phi)}
\end{align*}</script><p>Q.E.D</p>
]]></content>
      <categories>
        <category>Bayesian Data Analysis</category>
      </categories>
      <tags>
        <tag>Bayesian Data Analysis</tag>
      </tags>
  </entry>
  <entry>
    <title>Bayesian Data Analysis（一）：概率与推断</title>
    <url>/2021/11/27/20211127_Bayesian-Data-Analysis%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E6%A6%82%E7%8E%87%E4%B8%8E%E6%8E%A8%E6%96%AD/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>本次开启一个全新系列，贝叶斯数据分析系列。这一系列主要针对已经对基础的统计学知识如微积分、全概率模型、贝叶斯公式以及经典假设检验有了一定了解的同学，没有这些基础知识的话，看起来可能会比较吃力一些。从我目前掌握的程度看，贝叶斯数据分析对于一般的实验分析可能帮助不大，在日常中我们更多的是使用经典假设检验。贝叶斯数据分析在我看来提供了以下信息：</p>
<ul>
<li>一个新的分析视角。贝叶斯数据分析的整个分析步骤其实更贴近人的主观思考过程。它向我们展示了，我们在获得先验知识之后，为什么会在观测到一些样本信息后反而更新了我们的认知。</li>
<li>为频率学派难以解决的一些问题提供了一些新思路。这点主要集中在多重比较问题上。贝叶斯学派对于多重比较问题，其解决办法会更自然，更简单，而在频率学派下虽然我们也有着相应的一套解法，但其解法更复杂，因此在日常分析中没有办法使用。</li>
<li>对于很多统计或机器学习模型的基础。很多机器学习模型，实际上也在使用贝叶斯数据分析的思想。</li>
</ul>
<p>在开启这一新系列时，需要跟明确一些最基本的概念与所使用的符号。</p>
<h1 id="符号和基础信息"><a href="#符号和基础信息" class="headerlink" title="符号和基础信息"></a>符号和基础信息</h1><h2 id="两种未观测到的估计：统计推断中的未观测数据"><a href="#两种未观测到的估计：统计推断中的未观测数据" class="headerlink" title="两种未观测到的估计：统计推断中的未观测数据"></a>两种未观测到的估计：统计推断中的未观测数据</h2><p>如果我们在文章中提到未观测的数据，其一般有两种可能：</p>
<ol>
<li>潜在的观测数据（比如未来实验中会出现的，或当前实验结果未出现的）</li>
<li>数据无法被直接观测到的，比如控制着观察数据产生的假设过程的参数（比如回归估计的系数）</li>
</ol>
<p>这两类未观测数据的作用是完全不同的，在使用时务必将其分开。</p>
<h2 id="参数、数据和预测"><a href="#参数、数据和预测" class="headerlink" title="参数、数据和预测"></a>参数、数据和预测</h2><p>在全系列，我们使用$\theta$表示为我们关注的观测的向量或总体参数（比如每个实验中病人的生存概率），$y$表示为我们的观测数据（比如每个实验组中病人生存和死亡的数量），$\widetilde{y}$表示为我们未知的或潜在的观测数据（比如下次抽查中病人的生存或者死亡的情况）。同时约定希腊字母表示参数。小写罗马字母表示观测或未观测的标量或向量（向量为列向量），大写罗马字母表示矩阵。不加说明$p$表示概率密度，$F$表示累计概率分布，$Pr$表示累计概率。</p>
<h1 id="贝叶斯数据分析的基本步骤"><a href="#贝叶斯数据分析的基本步骤" class="headerlink" title="贝叶斯数据分析的基本步骤"></a>贝叶斯数据分析的基本步骤</h1><h2 id="概述：三个步骤"><a href="#概述：三个步骤" class="headerlink" title="概述：三个步骤"></a>概述：三个步骤</h2><ol>
<li>建立起一个<strong>全概率模型</strong>。问题中所有观测样本和未观测样本的联合概率密度。模型必须与科学研究问题蕴含的知识以及数据收集过程相关</li>
<li>基于观测样本进行条件化。计算和解释合适的<strong>后验分布</strong>——在给定观测样本的条件下，关于未观测样本的条件概率分布</li>
<li>评估模型拟合情况和结果后验分布的启示。模型是否很好地拟合了数据？实质性结论是否可信？以及模型对于前面的假设1（数据拟合程度）的敏感性如何？最终，如果不满足其一都有可能让我们修改和拓展模型，然后重新完成这三个步骤。<h2 id="理论：贝叶斯推断"><a href="#理论：贝叶斯推断" class="headerlink" title="理论：贝叶斯推断"></a>理论：贝叶斯推断</h2><h3 id="全概率模型"><a href="#全概率模型" class="headerlink" title="全概率模型"></a>全概率模型</h3></li>
</ol>
<p>在给定参数$\theta$的分布及其先验分布，我们从全概率公式出发，知道$\theta$和$y$的联合概率分布可以表达为</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\theta, y) = p(\theta)p(y \mid \theta)
\end{align*}</script><p>其中$\theta$的先验分布和其本身的分布并不等价，这在下一篇章会具体提到</p>
<h3 id="贝叶斯公式"><a href="#贝叶斯公式" class="headerlink" title="贝叶斯公式"></a>贝叶斯公式</h3><p>同时，根据给定给定观测数据$y$后，应用我们的贝叶斯法则，可以将<strong>后验密度分布</strong>表示为</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\theta \mid y) = \frac{p(\theta, y)}{p(y)} = \frac{p(\theta)p(y \mid \theta)}{p(y)}
\end{align*}</script><p>其中$p(y)=\sum_{\theta}p(\theta)p(y \mid \theta)$（连续情形下为$p(y)=\int_{\theta}p(\theta)p(y \mid \theta)$）</p>
<p>一旦观测数据$y$确定了，那么观测数据$y$的<strong>边缘概率密度</strong>也就是固定的，因此在这个贝叶斯公式中，我们可以认为<strong>观测数据$y$的边缘概率密度仅仅起到一个调节作用</strong>，也就是说</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\theta \mid y) \propto p(\theta)p(y \mid \theta)
\end{align*}</script><p><strong>但正比于不等同于完全相等，在使用时务必注意</strong></p>
<h3 id="后验预测分布"><a href="#后验预测分布" class="headerlink" title="后验预测分布"></a>后验预测分布</h3><p>在拥有后验分布后，我们假定未来想要观测数据$\widetilde{y}$出现的可能的分布，我们可以表示为$p(\widetilde{y} \mid y)$，根据贝叶斯法则，在连续情形下可以表示为</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\widetilde{y} \mid y) &= \int p(\widetilde{y}, \theta \mid y) d\theta\\
&= \int p(\widetilde{y} \mid y, \theta) p(\theta \mid y) d\theta\\
&= \int p(\widetilde{y} \mid \theta) p(\theta \mid y) d\theta \quad \mbox{(未观测数据的抽取与已观测数据无关，i.i.d假设)}\\
\end{align*}</script><p><strong>第2、3行表示后验预测分布可以看成是在$\theta$的后验分布下的条件预测值的平均</strong></p>
<h3 id="后验分布比"><a href="#后验分布比" class="headerlink" title="后验分布比"></a>后验分布比</h3><p>如果要计算两个参数的后验分布比，可以使用下式</p>
<script type="math/tex; mode=display">
\begin{align*}
\frac{p(\theta_{1} \mid y)}{p(\theta_{2} \mid y)} 
= \frac{p(\theta_{1})p(y \mid \theta_{1})/p(y)}{p(\theta_{2})p(y \mid \theta_{2})/p(y)}
=\frac{p(\theta_{1})p(y \mid \theta_{1})}{p(\theta_{2})p(y \mid \theta_{2})}
=\frac{p(\theta_{1})}{p(\theta_{2})}\frac{p(y \mid \theta_{1})}{p(y \mid \theta_{2})}
\end{align*}</script><p>$\frac{p(\theta_{1})}{p(\theta_{2})}$是$\theta$的先验分布比，$\frac{p(\theta_{1} \mid y)}{p(\theta_{2} \mid y)} $是后验分布比</p>
<h1 id="可交换性（非常重要的概念）"><a href="#可交换性（非常重要的概念）" class="headerlink" title="可交换性（非常重要的概念）"></a>可交换性（非常重要的概念）</h1><h2 id="可交换性（exchangeable）"><a href="#可交换性（exchangeable）" class="headerlink" title="可交换性（exchangeable）"></a>可交换性（exchangeable）</h2><p>对于一个有$n$个值（无限长的）的不确定性联合概率密度$p(y_{1}, \cdots, y_{n})$，我们认为每一个下标都是可交换的，也就是说不会收到样本顺序的影响。</p>
<p>看起来这个和i.i.d假设非常类似，但实际上可交换性与独立同分布(i.i.d)并不等价，<strong>可交换的随机变量不一定是独立同分布的，但独立同分布的可以满足可交换性。</strong></p>
<p>那这个性质是如何推导出来的呢？这里就不得不提到非常著名的De Finetti’s Theorem了。</p>
<blockquote>
<p>为方便起见，未经特殊说明，在本系列我们认为$y_{i}$是满足i.i.d假设的。</p>
<h2 id="De-Finetti’s-Theorem"><a href="#De-Finetti’s-Theorem" class="headerlink" title="De Finetti’s Theorem"></a>De Finetti’s Theorem</h2><h3 id="基本定义"><a href="#基本定义" class="headerlink" title="基本定义"></a>基本定义</h3><p>一个随机变量序列$(y_{1}, y_{2}, \cdots, y_{n})$是无限任意可交换的（infinite exchangeable）当且仅当相同度量空间下的$p$和$\theta$，$\forall n \in N$</p>
<script type="math/tex; mode=display">
\begin{align*}
p(y_{1}, y_{2}, \cdots, y_{n})=\int \prod_{i=1}^{n}p(y_{i} \mid \theta) d p(\theta)
\end{align*}</script></blockquote>
<h3 id="意义"><a href="#意义" class="headerlink" title="意义"></a>意义</h3><p>虽然这个定理看起来这么简单，但是实际上这一定理几乎是后续很多统计或机器学习模型能够成立的一个重要基础，在我看来这一定理的意义在于：</p>
<ul>
<li>先验分布的信息来自于历史的数据和经验，我们无需刻意的假定先验分布的存在。以抛硬币为例，如果我的先验认知是硬币的正反两面出现的概率相等，这是无限多的历史数据和经验积累出来的结果。</li>
<li>在无限多样本的情况下，前n-1次的数据结果不会影响我们对第n次事件发生的最初始先验概率的认知。以抛硬币为例，如果我的认知是硬币的正反两面出现的概率相等，那么即使前9999次出现的概率是正面，我在第10000次事件发生前的先验认知也不会发生改变，依旧是$\frac{1}{2}$。</li>
<li>提出了在某些情形下，可交换随机变量满足条件独立的条件。</li>
</ul>
<blockquote>
<p>注意：对于有限长度的序列，这一定理并不生效。举个两个例子：</p>
<ol>
<li>假设箱子里有一个白球一个黑球，那么在不放回的随机抽出第一个球后，第二个球的信息实际上已经已知了（先验信息发生了变化）</li>
<li>假定在有放回的随机抽出第一个球后，第二次抽取时，先验信息还是未发生改变。这个和抛硬币的例子是类似的。</li>
</ol>
</blockquote>
<h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><h2 id="均值与方差"><a href="#均值与方差" class="headerlink" title="均值与方差"></a>均值与方差</h2><p>假定存在随机变量$u$和$v$，且两个变量具有相关性，考虑连续情形。随机变量$u$的期望和方差可以表示为</p>
<script type="math/tex; mode=display">
\begin{align*}
E(u) &= \int up(u)du\\
var(u) &=  \int (u-E(u))^{2}du = E(u^{2})-(E(u))^{2}
\end{align*}</script><p>若随机变量$u$为向量形式，那么协方差矩阵可以表示为</p>
<script type="math/tex; mode=display">
\begin{align*}
cov(u) &=  \int (u-E(u))(u-E(u))^{T}du
\end{align*}</script><p>期望迭代公式：在给定$v$的边缘分布情形下</p>
<script type="math/tex; mode=display">
\begin{align*}
E(u) &= \iint up(u,v)dudv\\
&= \iint up(u \mid v) p(v) dudv\\
&= \int_{v} E(u \mid v) p(v) dv\\
&= E_{v}(E_{u}(u \mid v))
\end{align*}</script><p>同时关于方差，我们可以表示为</p>
<script type="math/tex; mode=display">
\begin{align*}
var(u) &= E(u^{2})-(E(u))^{2}\\
&= E(u^{2})-E\{(E(u \mid v))^{2}\}+E\{(E(u \mid v))^{2}\}-(E(u))^{2}\\
&= E\{E(u^{2} \mid v)\}-E\{(E(u \mid v))^{2}\}+E\{(E(u \mid v))^{2}\}-(E\{E(u \mid v)\})^{2} \quad \mbox{（应用上面的期望迭代公式）}\\
&= E\{E(u^{2} \mid v)-(E(u \mid v))^{2}\}+(E\{(E(u \mid v))^{2}\}-(E\{E(u \mid v)\})^{2})\\
&= E(var(u \mid v)) + var(E(u \mid v))\\
\end{align*}</script>]]></content>
      <categories>
        <category>Bayesian Data Analysis</category>
      </categories>
      <tags>
        <tag>Bayesian Data Analysis</tag>
      </tags>
  </entry>
  <entry>
    <title>20220501_Bayesian Data Analysis（五）：分层模型【WIP】</title>
    <url>/2021/05/01/20220501-Bayesian-Data-Analysis%EF%BC%88%E4%BA%94%EF%BC%89%EF%BC%9A%E5%88%86%E5%B1%82%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="前言：一个例子"><a href="#前言：一个例子" class="headerlink" title="前言：一个例子"></a>前言：一个例子</h1><h2 id="事件背景"><a href="#事件背景" class="headerlink" title="事件背景"></a>事件背景</h2><p>这个是Bayesian Data Analysis这本书的一个例子，假如我们做了一个小鼠药物肿瘤发病率的实验，由于书中的数据实在太多，我这边就瞎构建一些：</p>
<p><style type="text/css"><br>.tg  {border-collapse:collapse;border-spacing:0;}<br>.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;<br>  overflow:hidden;padding:10px 5px;word-break:normal;}<br>.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;<br>  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}<br>.tg .tg-c3ow{border-color:inherit;font-weight:bold;font-size:18px;text-align:center;vertical-align:top}<br>.tg .tg-0pky{border-color:inherit;text-align:center;vertical-align:top}
</style></p>
<table class="tg">
<colgroup>
<col style="width: 180px">
<col style="width: 180px">
<col style="width: 180px">
</colgroup>
<thead>
  <tr>
    <th class="tg-c3ow" colspan="3">实验结果</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-0pky">0/20</td>
    <td class="tg-0pky">0/20</td>
    <td class="tg-0pky">0/20</td>
  </tr>
  <tr>
    <td class="tg-0pky">2/17</td>
    <td class="tg-0pky">3/18</td>
    <td class="tg-0pky">2/19</td>
  </tr>
  <tr>
    <td class="tg-0pky">0/18</td>
    <td class="tg-0pky">0/20</td>
    <td class="tg-0pky">4/21</td>
  </tr>
  <tr>
    <td class="tg-0pky">2/19</td>
    <td class="tg-0pky">5/16</td>
    <td class="tg-0pky">4/14</td>
  </tr>
</tbody>
</table>

<p>可以看到，这12次实验每次实验的样本数不统一，这个原因可能是多样的，比如实在12个不同的实验室下同时做的实验。现在想要知道肿瘤发病率$\theta$的分布（假定它服从共轭先验分布Beta分布），该如何求取Beta分布的两个参数呢？</p>
<h2 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h2><p>如果我们认为每次的实验结果，由于其实验室环境各不相同，因此小鼠的肿瘤发病率是不一样的，那么我们可以认为$\theta_{i}$直接影响了$y_{i}$（表示为$\theta_{i} \rightarrow y_{i}$），那么根据附录一中的方法二，我们可以得出，每家医院的肿瘤发病率满足</p>
<script type="math/tex; mode=display">
\begin{align*}
   \theta_{i} \sim Beta(y_{i}, n_{i}-y_{i}+1)
\end{align*}</script><h2 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h2><p>一种情况是，我们认为虽然各家实验室可能环境各不相同，但是小鼠肿瘤发病率都是受相同因素的影响，也就是说，对于每一个实验结果$y_{i}$，都满足$\theta \rightarrow y_{i}$。</p>
<p>在这种情况下，一种想法是，为了消除各实验室之间的差异，<strong>我们可以把所有实验结果加总</strong>，并根据附录一中的方法二，得到</p>
<script type="math/tex; mode=display">
\begin{align*}
   \theta \sim Beta(\sum y_{i}, \sum (n_{i}-y_{i})+1)
\end{align*}</script><h2 id="方法三"><a href="#方法三" class="headerlink" title="方法三"></a>方法三</h2><p><strong>第三种方法和第二种方法类似，只是消除各医院差异的方式是使用了均值和方差的信息（附录一中的方法一）。</strong></p>
<p>具体求解出这12次实验的均值和方差，并近似求解Beta分布的超参数。上述的例子中，均值为0.107，标准差为0.109，经计算后可得$\alpha=0.756,\beta=6.31$</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>在做完这一步后，我们需要问几个问题：</p>
<ul>
<li>这个方式求出的后验分布模型是贝叶斯统计推断的方式吗？</li>
<li>这种方法存在什么问题？</li>
<li>如果这种方法存在问题，那么我们该如何改进它？</li>
</ul>
<p>针对第1个问题，答案是肯定的。这个后验分布求解过程是一个贝叶斯统计推断模型。在前面几篇也讲过，我们贝叶斯统计推断的几个步骤：</p>
<ul>
<li>对先验分布$p(\theta)$做出假设</li>
<li>根据全概率模型，利用样本信息$y$求解出参数的后验分布$p(\theta \mid y)$</li>
<li>根据给定的新样本部分信息进行预测</li>
</ul>
<p>在这个过程里，我们应用了全部样本信息去求解了$\theta$的先验分布，并且在第二步里，虽然没有严格的使用全概率模型进行参数计算，但还是应用了样本本身的信息或者均值和方差的信息去更新了后验分布的参数。</p>
<blockquote>
<p>简单理解为我们对于每一次实验，$y_{i}$和$\theta_{i}$的值相等，只是我们在不同场合把实际实验的结果应用为不同的参数</p>
</blockquote>
<p>针对第2个问题，这个方法存在以下两个问题</p>
<ul>
<li>对于方法一，我们没有考虑到实验结果都是存在差异的，不存在共性问题，这不利于我们后续的应用。</li>
<li>参数的过度拟合问题。就像上面说的，我们应用了全部样本信息去求解了$\theta$的先验分布，并且再次利用样本本身的信息或者均值和方差的信息去更新了后验分布的参数。虽然我们计算过程只有一次，但请注意，我们并没有前置给定任何的先验分布的具体信息。</li>
<li>无法确定$\theta$的超参数能否被估计。正如前面所说，$\theta$的先验分布是由我们给定的样本信息求出的，但是我们又应用了它们去求解后验分布。问题是，先验分布的信息能否在更前置的环节获得呢？</li>
</ul>
<h1 id="分层模型"><a href="#分层模型" class="headerlink" title="分层模型"></a>分层模型</h1><h2 id="三类模型"><a href="#三类模型" class="headerlink" title="三类模型"></a>三类模型</h2><h3 id="独立模型（separate-model）"><a href="#独立模型（separate-model）" class="headerlink" title="独立模型（separate model）"></a>独立模型（separate model）</h3><p>在前面例子的方法一中，我们认为其实验室环境各不相同，因此小鼠的肿瘤发病率不同（$\theta_{i} \rightarrow y_{i}$），这实际上就是独立模型，如果用图来表示为</p>
<pre class="mermaid">flowchart TD
x1("&theta;<sub>1</sub>")
x2("&theta;<sub>2</sub>")
x3("...")
x4("&theta;<sub>n</sub>")
y1("y<sub>1</sub>")
y2("y<sub>2</sub>")
y3("...")
y4("y<sub>n</sub>")

x1-->y1;
x2-->y2;
x3-->y3;
x4-->y4;</pre>
### 合并模型（pooled model）
在前面提到的方法二和方法三，我们认为不管实验结果受不受各个实验环境的影响，小鼠的肿瘤发病率实验都是受到某些共同因素的影响，这一因素的数值体现就是$\theta$，也就是说$\theta \rightarrow y_{i}$。这一方式用图体现为
<pre class="mermaid">flowchart TD
x1("&theta;")

y1("y<sub>1</sub>")
y2("y<sub>2</sub>")
y3("...")
y4("y<sub>n</sub>")

x1-->y1;
x1-->y2;
x1-->y3;
x1-->y4;</pre>
### 分层模型（hierarchical model）
至于分层模型，则是另一种解法。正如上面提到的第3个问题，如果我们能够知道前置知道肿瘤发病率的先验分布信息，而不是在获得实际肿瘤实验数据是进行求解，那么这个问题似乎就变得迎刃而解了。比如小鼠肿瘤发病率的共性信息用$\phi$表示，不同的实验环境存在着实验差异，但其共性的部分都受到共性信息的控制，即$\phi \rightarrow \theta_{i}$，而每个实验的实验环境最终也就影响到了最终的实验结果，即$\theta_{i} \rightarrow y_{i}$，这样一来，整个逻辑链路就变得清晰明了，整个模型用图来表示为
<pre class="mermaid">flowchart TD
s("&phi;")
x1("&theta;<sub>1</sub>")
x2("&theta;<sub>2</sub>")
x3("...")
x4("&theta;<sub>n</sub>")
y1("y<sub>1</sub>")
y2("y<sub>2</sub>")
y3("...")
y4("y<sub>n</sub>")

s-->x1;
s-->x2;
s-->x3;
s-->x4;
x1-->y1;
x2-->y2;
x3-->y3;
x4-->y4;</pre>

<h2 id="分层模型确定的步骤"><a href="#分层模型确定的步骤" class="headerlink" title="分层模型确定的步骤"></a>分层模型确定的步骤</h2><h3 id="先验分布的确定"><a href="#先验分布的确定" class="headerlink" title="先验分布的确定"></a>先验分布的确定</h3><p>假设我们的肿瘤发病实验的结果$\theta_{i}$受到一个未知参数$\phi$控制的先验分布的影响，由于各实验结果是相互独立的，因此</p>
<script type="math/tex; mode=display">
\begin{align*}
    p(\theta \mid \phi) = \prod_{i=1}^{n} p(\theta_{i} \mid \phi)
\end{align*}</script><p>对应的，$\theta$的分布可以表示为</p>
<script type="math/tex; mode=display">
\begin{align*}
    p(\theta) = \int p(\theta \mid \phi)p(\phi) d\phi = \int [\prod_{i=1}^{n} p(\theta_{i} \mid \phi)]p(\phi) d\phi
\end{align*}</script><p><strong>当$n \rightarrow \infty$时</strong>，满足De Finetti’s Theorem（第一篇有提到），此时说明$\theta$这一参数实际上受一个未知超参数$\phi$的控制</p>
<p>如果有额外的信息$x$，使得我们的随机变量$y$不满足可交换性，但是$(y_{i}, x_{i})$整体满足可交换性，那么可以通过构造$y \mid x$这一条件独立模型</p>
<h3 id="分层模型的确定"><a href="#分层模型的确定" class="headerlink" title="分层模型的确定"></a>分层模型的确定</h3><p>由全概率模型以及贝叶斯公式可以得知</p>
<script type="math/tex; mode=display">
\begin{align*}
    p(\phi, \theta \mid y) &= \frac{p(\phi, \theta, y)}{p(y)}\\
    &= \frac{p(\phi, \theta)p(y \mid \phi, \theta)}{p(y)}\\ 
    &= \frac{p(\phi)p(\theta \mid \phi)p(y \mid \phi, \theta)}{p(y)}\\ 
\end{align*}</script><p>由于$\theta$是受超参数$\phi$的控制，超参数$\phi$对$y$的影响是通过参数$\theta$完成的，因此$p(y \mid \phi, \theta)=p(y \mid \theta)$，即</p>
<script type="math/tex; mode=display">
\begin{align*}
    p(\phi, \theta \mid y) &= \frac{p(\phi)p(\theta \mid \phi)p(y \mid \theta)}{p(y)}\\ 
\end{align*}</script><p>这样，一个双层的分层模型的基本形式就出来了。</p>
<blockquote>
<p>额外的话：<br>假定我们的超参数$\phi$受到另外的超参数$\zeta$的控制，那么可以构建一个三层模型，其基本形式为</p>
<script type="math/tex; mode=display">
\begin{align*}
    p(\phi, \theta, \zeta, \mid y) &= \frac{p(\zeta)p(\phi \mid \zeta)p(\theta \mid \phi)p(y \mid \theta)}{p(y)}\\ 
\end{align*}</script><p>更多层的模型形式以此类推</p>
</blockquote>
<p>以双层模型为例，实际上这个模型的右侧可以看成是三个模型的组合，其中$p(\phi)$表示我们的一个大前提，也可以看成是一个先验模型；$p(\theta \mid \phi)$表示一个组间模型，即在给定先验信息的情况下，各组表现的差异信息；$p(y \mid \theta)$表示一个组内模型，即在给定组间先验信息的情况下，各组组内表现的差异信息。</p>
<h2 id="超参数的计算"><a href="#超参数的计算" class="headerlink" title="超参数的计算"></a>超参数的计算</h2><p>在分层模型确定后，我们需要做的是将各个参数或各个参数的分布进行求解，这其中，最关键的地方就是超参数（分布）的确定。<br>还是以前面的小鼠肿瘤实验的例子，假设肿瘤发病数满足$y_{i} \sim Bin(n_{i}, \theta_{i})$，而肿瘤发病率满足$\theta_{i} \sim Beta(\alpha, \beta)$，那么$(\alpha, \beta)$就是我们需要确定的一组超参数，利用分层模型，我们可以快速得出</p>
<script type="math/tex; mode=display">
\begin{align*}
    p(\theta, \alpha, \beta \mid y) &\approx p(\alpha, \beta)p(\theta \mid \alpha, \beta)p(y \mid \theta)\\
    &\approx p(\alpha, \beta)\prod_{i=1}^{n} p(\theta_{i} \mid \alpha, \beta)\prod_{i=1}^{n}p(y_{i} \mid \theta_{i}) \quad \mbox{(每次实验的结果独立)}\\
    &=p(\alpha, \beta)\prod_{i=1}^{n} \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta_{i}^{\alpha-1}(1-\theta_{i})^{\beta-1} 
    \prod_{i=1}^{n} 
    \begin{pmatrix}
      n_{i}\\
      y_{i}
    \end{pmatrix}
    \theta_{i}^{y_{i}}(1-\theta_{i})^{n_{i}-y_{i}}
\end{align*}</script><p>这其中，一旦$(\alpha, \beta)$确定，上式便可求出。另外，当$(\alpha, \beta)$确定后，参数的后验分布，也同样可以得到（$p(\theta \mid \alpha, \beta, y)$和$p(\alpha, \beta \mid y)$）</p>
<blockquote>
<p>注意：<br>$\theta_{i}$在模型里并不直接等于$\frac{y_{i}}{n_{i}}$，$\theta_{i}$更像是一个先验分布的概念</p>
</blockquote>
<p>一般来说，超参数是未知的，我们只能通过对超参数分布进行预设来进行求解，一旦超参数设定偏差很大，就像前面说过的，选择了不恰当先验分布，很有可能会得到不正确的结果。在书中对于$(\alpha, \beta)$的分布，作者预设了$p(\alpha, \beta) \approx (\alpha, \beta)^{-\frac{5}{2}}$得到了一系列结果。</p>
<blockquote>
<p>P.S. 所以说调参就像炼丹</p>
</blockquote>
<h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><h2 id="附录一：针对二项分布对应的Beta分布，近似求解超参数"><a href="#附录一：针对二项分布对应的Beta分布，近似求解超参数" class="headerlink" title="附录一：针对二项分布对应的Beta分布，近似求解超参数"></a>附录一：针对二项分布对应的Beta分布，近似求解超参数</h2><p>方法一：</p>
<script type="math/tex; mode=display">
\begin{align*}
    \alpha + \beta &= \frac{E(\theta)(1-E(\theta))}{var(\theta)}-1\\
    \alpha &= (\alpha + \beta)E(\theta)\\
    \beta &= (\alpha + \beta)(1-E(\theta))
\end{align*}</script><p>方法二：<br>同时对于一个n个独立的服从$[0, 1]$均匀分布的样本，第$k$个的<strong>次序统计量</strong>服从$Beta(k, n-k+1)$，而二项分布，恰好可以使用这种方法求解</p>
]]></content>
      <categories>
        <category>Bayesian Data Analysis</category>
      </categories>
      <tags>
        <tag>Bayesian Data Analysis</tag>
      </tags>
  </entry>
  <entry>
    <title>Dataframe设置条件格式</title>
    <url>/2021/01/25/20210125_Dataframe%E6%9D%A1%E4%BB%B6%E6%A0%BC%E5%BC%8F/</url>
    <content><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><h1 id="设置条件格式"><a href="#设置条件格式" class="headerlink" title="设置条件格式"></a>设置条件格式</h1><h2 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h2><p><a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/style.html">https://pandas.pydata.org/pandas-docs/stable/user_guide/style.html</a></p>
<p>rgb和十六进制颜色互转（可再写篇文章）<br><a href="https://www.sioe.cn/yingyong/yanse-rgb-16/">https://www.sioe.cn/yingyong/yanse-rgb-16/</a></p>
<h2 id="对于多条件的条件格式的设置（重点）"><a href="#对于多条件的条件格式的设置（重点）" class="headerlink" title="对于多条件的条件格式的设置（重点）"></a>对于多条件的条件格式的设置（重点）</h2>]]></content>
      <categories>
        <category>DataFrame</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Dataframe</tag>
      </tags>
  </entry>
  <entry>
    <title>Dataframe的多级索引</title>
    <url>/2021/01/19/20210119_DataFrame%E5%A4%9A%E7%BA%A7%E7%B4%A2%E5%BC%95%E5%A2%9E%E5%8A%A0%E8%A1%8C/</url>
    <content><![CDATA[<h1 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h1><p>一般来说Dataframe的索引都是单一索引。学过数据库的话会知道有时候单个属性作为索引较为单薄，例如下面的成绩表</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>姓名</th>
<th>科目</th>
<th>成绩</th>
</tr>
</thead>
<tbody>
<tr>
<td>Mike</td>
<td>Math</td>
<td>90</td>
</tr>
<tr>
<td>Mike</td>
<td>Chinese</td>
<td>85</td>
</tr>
<tr>
<td>Bob</td>
<td>English</td>
<td>70</td>
</tr>
<tr>
<td>Amy</td>
<td>Math</td>
<td>99</td>
</tr>
<tr>
<td>Amy</td>
<td>English</td>
<td>96</td>
</tr>
</tbody>
</table>
</div>
<p>无论是单用姓名还是科目，都没有办法很好的发挥索引的功能（例如假设姓名可以作为索引，那么我可以利用Mike这个姓名找到唯一的一个成绩，但事实上我可以找到两个），但是（姓名，科目）却可以唯一的找到成绩。这个（姓名，科目）便是我们的联合索引。因此在实际中我们有可能会用到这样的索引形式（虽然在Dataframe中没有这个必要单独设置成这样）。</p>
<p>在Dataframe中我们有多级索引（multiindex）。多级索引实际上是联合索引的一种，只是将索引层级化，用前面的例子，如果我们设置的多级索引是（姓名，科目），那么我们最终得到的表的形式应该是：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>姓名</th>
<th>科目</th>
<th>成绩</th>
</tr>
</thead>
<tbody>
<tr>
<td>Mike</td>
<td>Math</td>
<td>90</td>
</tr>
<tr>
<td></td>
<td>Chinese</td>
<td>85</td>
</tr>
<tr>
<td>Bob</td>
<td>English</td>
<td>70</td>
</tr>
<tr>
<td>Amy</td>
<td>Math</td>
<td>99</td>
</tr>
<tr>
<td></td>
<td>English</td>
<td>96</td>
</tr>
</tbody>
</table>
</div>
<p>但如果设置的多级索引是（科目，姓名），那么我们最终得到的表的形式应该是：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>科目</th>
<th>姓名</th>
<th>成绩</th>
</tr>
</thead>
<tbody>
<tr>
<td>Math</td>
<td>Mike</td>
<td>90</td>
</tr>
<tr>
<td></td>
<td>Amy</td>
<td>99</td>
</tr>
<tr>
<td>Chinese</td>
<td>Mike</td>
<td>85</td>
</tr>
<tr>
<td>English</td>
<td>Bob</td>
<td>70</td>
</tr>
<tr>
<td></td>
<td>Amy</td>
<td>96</td>
</tr>
</tbody>
</table>
</div>
<p>但无论是哪种形式的多级索引，我们都能够用这样的索引找到对于的成绩</p>
<h1 id="创建多级索引"><a href="#创建多级索引" class="headerlink" title="创建多级索引"></a>创建多级索引</h1><p>在Dataframe中我们有很多种种方法创建多级索引。如果我们仔细观察不难发现当我们查看一个Dataframe（简便起见后称df）的索引时，我们得到的是一个Index对象（pandas.Index)。而多级索引则更进一步，其索引为MultiIndex对象，因此，多级索引可以利用MultiIndex对象来创建。其中最常用的方法是利用pd.MultiIndex.from_arrays和pd.MultiIndex.from_product来创建。</p>
<p>以我们的第一张多级索引表为例，如果我们有了分数序列(90, 85, 70, 99, 96)，我们可以使用以下代码创建出该Dataframe：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">scores = [<span class="number">90</span>, <span class="number">85</span>, <span class="number">70</span>, <span class="number">99</span>, <span class="number">96</span>]</span><br><span class="line">df = pd.DataFrame(</span><br><span class="line">        data=scores,</span><br><span class="line">        index=pd.MultiIndex.from_arrays(</span><br><span class="line">            arrays=[[<span class="string">&#x27;Mike&#x27;</span>, <span class="string">&#x27;Mike&#x27;</span>, <span class="string">&#x27;Bob&#x27;</span>, <span class="string">&#x27;Amy&#x27;</span>, <span class="string">&#x27;Amy&#x27;</span>], [<span class="string">&#x27;Math&#x27;</span>, <span class="string">&#x27;Chinese&#x27;</span>, <span class="string">&#x27;English&#x27;</span>, <span class="string">&#x27;Math&#x27;</span>, <span class="string">&#x27;English&#x27;</span>]], </span><br><span class="line">            names=[<span class="string">&#x27;姓名&#x27;</span>, <span class="string">&#x27;科目&#x27;</span>]),</span><br><span class="line">        columns=[<span class="string">&#x27;成绩&#x27;</span>]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">print(df)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>其中pd.MultiIndex.from_arrays的第一个参数是一个arrays，即索引的具体信息，放置在第一层的sequence是第一级索引，以此类推。不仅如此我们还可以用names参数给索引命名，像本例给索引命名为姓名和科目。</p>
<blockquote>
<p>需要注意的是，如果构建原表的话，姓名和科目是作为属性在columns中命名，但此刻我们将它作为了索引，因此只能在index中构建<br>除了行索引(index)，我们还可以建立列(columns)的多级索引，在此不再重复，感兴趣的读者可以自行尝试。<br>pd.MultiIndex.from_product其实用的是笛卡尔积的原理，例如我们想要向该方法传入&#91;&#91;&#39;A&#39;,&#39;B&#39;&#93;&#91;&#39;C&#39;,&#39;D&#39;&#93;&#93;，最终我们得到的是AC,AD,BC,BD四个索引，在此不做展示了</p>
</blockquote>
<p>除了这种方法，我们也可以从原表中设置多级索引，例如在我们获取原表后，可以用如下代码实现多级索引的构建：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建原表的DataFrame</span></span><br><span class="line">...</span><br><span class="line"><span class="comment"># 设置多级索引</span></span><br><span class="line">df.set_index([<span class="string">&#x27;姓名&#x27;</span>, <span class="string">&#x27;科目&#x27;</span>], inplace=<span class="literal">True</span>)</span><br><span class="line">print(df)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="多级索引的切片"><a href="#多级索引的切片" class="headerlink" title="多级索引的切片"></a>多级索引的切片</h1><p>多级索引的切片和一般索引的切片并无二致，以我们的第一张多级索引表为例，尝试使用以下代码理解：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建第一张多级索引表的DataFrame</span></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">print(df.loc[<span class="string">&#x27;Mike&#x27;</span>, :])  </span><br><span class="line"><span class="comment"># 科目         </span></span><br><span class="line"><span class="comment"># Math     90</span></span><br><span class="line"><span class="comment"># Chinese  85</span></span><br><span class="line">print(df.loc[<span class="string">&#x27;Mike&#x27;</span>, :].loc[<span class="string">&#x27;Math&#x27;</span>, :])</span><br><span class="line"><span class="comment"># 成绩  90</span></span><br><span class="line"><span class="comment"># Name: (Mike, Math), dtype: int64</span></span><br><span class="line">print(df.loc[(<span class="string">&#x27;Mike&#x27;</span>, <span class="string">&#x27;Math&#x27;</span>), :])  </span><br><span class="line"><span class="comment"># 成绩  90</span></span><br><span class="line"><span class="comment"># Name: (Mike, Math), dtype: int64</span></span><br><span class="line">print(df.iloc[<span class="number">0</span>, :])</span><br><span class="line"><span class="comment"># 成绩  90</span></span><br><span class="line"><span class="comment"># Name: (Mike, Math), dtype: int64</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<blockquote>
<p>若索引为中文可能会报错，此为pandas中文兼容性问题</p>
</blockquote>
<h1 id="多级索引增加行"><a href="#多级索引增加行" class="headerlink" title="多级索引增加行"></a>多级索引增加行</h1><p>在创建多级索引后增加行是pandas中比较bug的一个操作，后续等待修复，但目前为止仅尝试出以下方法是成立的。以我们的第一张多级索引表为例，如果我们想要在Bob的名下加上English的分数86，必须得使用以下代码:<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建第一张多级索引表的DataFrame</span></span><br><span class="line">...</span><br><span class="line"><span class="comment"># 正确做法</span></span><br><span class="line">df.loc[(<span class="string">&#x27;Bob&#x27;</span>, <span class="string">&#x27;English&#x27;</span>), :] = <span class="number">86</span></span><br><span class="line"><span class="comment"># 错误做法(这些做法是将原表做了copy操作，但实际上原表并未修改)</span></span><br><span class="line">df.loc[(<span class="string">&#x27;Bob&#x27;</span>, <span class="string">&#x27;English&#x27;</span>), :] = <span class="number">86</span></span><br><span class="line">df.loc[(<span class="string">&#x27;Bob&#x27;</span>, <span class="string">&#x27;English&#x27;</span>)] = <span class="number">86</span></span><br><span class="line">df.loc[<span class="string">&#x27;Bob&#x27;</span>, :].loc[<span class="string">&#x27;English&#x27;</span>, :] = <span class="number">86</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>这可能是一个pandas的一个bug，需要特别注意</p>
</blockquote>
<h1 id="说在最后"><a href="#说在最后" class="headerlink" title="说在最后"></a>说在最后</h1><p>一般多级索引不会直接使用，很多情况下我们会在使用了groupby操作后产生多级索引，该篇最初的背景是作者在写毕业论文中遇到的一个小问题，虽然问题很小，但确实困扰了很久，因此特地记录一下。</p>
]]></content>
      <categories>
        <category>DataFrame</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Dataframe</tag>
      </tags>
  </entry>
  <entry>
    <title>Python实现线性回归</title>
    <url>/2021/01/01/20210101_Python%E5%AE%9E%E7%8E%B0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</url>
    <content><![CDATA[<h1 id="最小二乘法求解线性回归的基本原理"><a href="#最小二乘法求解线性回归的基本原理" class="headerlink" title="最小二乘法求解线性回归的基本原理"></a>最小二乘法求解线性回归的基本原理</h1><p>如果一组自变量$x$和因变量$y$存在线性关系，那么可以用如下方程表示他们的线性关系：</p>
<script type="math/tex; mode=display">
y_{i}=b_{0}+b_{1}x_{i1}+b_{2}x_{i2}+\dots++b_{p}x_{ip}+\epsilon_{i} \tag{1} \label{eq1}</script><p>其中$i$表示第$i$个方程，$\epsilon_{i}$是随机误差且满足$\epsilon_{i} \sim N(0, \sigma^{2})$。</p>
<p>如果把$y_{i}$看成关于是$\epsilon_{i}$的随机变量，那么由$\epsilon_{i}$的性质，可以得到如下关系：</p>
<script type="math/tex; mode=display">
E(y_{i}|x_{i1}, x_{i2}, x_{ip})=b_{0}+b_{1}x_{i1}+b_{2}x_{i2}+\dots++b_{p}x_{ip} \tag{2} \label{eq2}</script><p>由公式<script type="math/tex">\eqref{eq1}\eqref{eq2}</script>可以得到：</p>
<script type="math/tex; mode=display">
y_{i}=E(y_{i}|x_{i1}, x_{i2}, x_{ip})+\epsilon_{i}</script><p>用矩阵可以表示为</p>
<script type="math/tex; mode=display">
\textbf{y=Xb}+\boldsymbol{\epsilon} \tag{3} \label{eq3}</script><p>其中</p>
<script type="math/tex; mode=display">
\begin{gathered}
\textbf{X}=
\begin{bmatrix}
1    &    x_{11}    &    \dots    &    x_{1p}    \\
1    &    x_{21}    &    \dots    &    x_{2p}    \\
\dots    &    \dots    &    \dots    &    \dots    \\
1    &    x_{n1}    &    \dots    &    x_{np}    \\
\end{bmatrix}
\end{gathered}，
\textbf{y}=(y_{1}, y_{2}, \dots, y_{n})^{T},
\boldsymbol{\epsilon} = (\epsilon_{1}, \epsilon_{2}, \dots, \epsilon_{n})^{T}</script><p>线性回归本质上就是在估计公式$\eqref{eq3}$的参数$\textbf{b}$</p>
<p>对于线性回归，一般来说，最常用的方法便是最小二乘法（至于为什么不直接用$\boldsymbol{X^{-1}y}$来估计$\boldsymbol{b}$可以见另外一篇文章「待定」）</p>
<p>最小二乘法通过最小化误差（残差）的平方和寻找数据的最佳的函数匹配，使得这些求得的数据与实际数据之间误差的平方和为最小。用数学语言描述为：</p>
<script type="math/tex; mode=display">
\min \quad \boldsymbol{\epsilon^{2}}=(\boldsymbol{y-E(y|X)})^{2} \tag{4} \label{eq4}</script><p>若满足以下2个条件：</p>
<ol>
<li>$\boldsymbol{X}$满秩</li>
<li>$\epsilon_{i}$是随机误差且满足$\epsilon_{i} \sim N(0, \sigma^{2})$</li>
</ol>
<p>则公式$\eqref{eq4}$存在解析解。</p>
<p>对参数$\textbf{b}$求偏导，并令其等于0:</p>
<script type="math/tex; mode=display">
\frac{\partial \boldsymbol{\epsilon^{2}}}{\partial \boldsymbol{b}}=2\boldsymbol{X^{T}(y-Xb)} \tag{5} \label{eq5}\\
\frac{\partial \boldsymbol{\epsilon^{2}}}{\partial \boldsymbol{b}}=0\\</script><p>解出：</p>
<script type="math/tex; mode=display">
\boldsymbol{b}=\boldsymbol{(X^{T}X)^{-1}X^{T}y}</script><blockquote>
<p>若满足以下2个条件：</p>
<ol>
<li>$\boldsymbol{X}$满秩</li>
<li>$\epsilon_{i}$是随机误差且满足$\epsilon_{i} \sim N(0, \sigma^{2})$</li>
</ol>
</blockquote>
<p>该条件是最小二乘法存在解析解的条件，但如果满足以下6个条件：</p>
<ol>
<li>参数线性。总体回归模型是线性模型，包括变量线性和参数线性，如</li>
<li>随机抽样。观测值$(x_{i1}, x_{i2}, \dots, x_{ip}, y_{i})$是对总体的随机抽烟，并且遵循公式$\eqref{eq1}$</li>
<li>满秩。自变量之间没有完全的线性关系</li>
<li>零条件均值。随机误差在每个观测点的条件均值为0</li>
<li>同方差假定。随机干扰项的条件方差固定</li>
<li>无序列相关性。即不同样本的随机误差取值不相关</li>
</ol>
<p>则最小二乘法得到的解析解是BLUE，无需再找其他解析解（高斯-马尔可夫定理）</p>
<h1 id="常见替代方法的原理及其应用"><a href="#常见替代方法的原理及其应用" class="headerlink" title="常见替代方法的原理及其应用"></a>常见替代方法的原理及其应用</h1><p>由求解的原理可以得知使用解析解估计线性模型参数$\boldsymbol{b}$的重要条件之一便是$\boldsymbol{X}$满秩，但在实际应用中我们常常遇到这两种情况：</p>
<ol>
<li>模型线性程度低</li>
<li>$\boldsymbol{X}$不满秩，即存在共线性问题</li>
</ol>
<p>因此解析解通常难以进行实际应用，下面将介绍几种常用的替代方法，用于解决实际的线性回归问题</p>
<h2 id="梯度下降法（Gradient-Descent-GD）"><a href="#梯度下降法（Gradient-Descent-GD）" class="headerlink" title="梯度下降法（Gradient Descent, GD）"></a>梯度下降法（Gradient Descent, GD）</h2><p>梯度的本意是一个向量（矢量），表示某一函数在该点处的方向导数沿着该方向取得最大值，即函数在该点处沿着该方向（此梯度的方向）变化最快，变化率最大（为该梯度的模）<a href="#refer-anchor-1"><sup>1</sup></a></p>
<p>该方法要解决的问题依旧是$\eqref{eq4}$，由梯度的定义不难看出，$\eqref{eq5}$便是梯度的计算公式，与求解析解不同的是，梯度下降法通过迭代来逼近最优解，其迭代公式如下：</p>
<script type="math/tex; mode=display">
\boldsymbol{b}=\boldsymbol{b}-\lambda \nabla_{b}\boldsymbol{\epsilon^{2}}</script><p>其中$\lambda$称为<strong>步长或者学习率</strong>，$\boldsymbol{\epsilon^{2}}=2\boldsymbol{X^{T}(y-Xb)} $，2只是常数，不影响迭代结果，可以改变成其他任意常数</p>
<p>如果非凸规划问题，则梯度下降法不一定找到全剧最优解而是陷入局部最优解。</p>
<p>根据使用样本的方法不同，梯度下降法常分为以下几种：</p>
<h3 id="批量梯度下降法（Batch-Gradient-Descent-BGD）"><a href="#批量梯度下降法（Batch-Gradient-Descent-BGD）" class="headerlink" title="批量梯度下降法（Batch Gradient Descent, BGD）"></a>批量梯度下降法（Batch Gradient Descent, BGD）</h3><p>批量梯度下降法在计算优化函数的梯度时利用<strong>全部样本数据</strong></p>
<p>迭代过程如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(max_iters):</span><br><span class="line">		grad = gradient(loss_function, y, x, b_old)</span><br><span class="line">		b_new = b_old - <span class="keyword">lambda</span>* grad</span><br><span class="line">		<span class="keyword">if</span> distance(b_new, b_old) &lt; sup:</span><br><span class="line">				end</span><br><span class="line">		end</span><br></pre></td></tr></table></figure>
<p>其中sup为收敛精度</p>
<h3 id="随机梯度下降（Stochastic-Gradient-Descent-SGD）"><a href="#随机梯度下降（Stochastic-Gradient-Descent-SGD）" class="headerlink" title="随机梯度下降（Stochastic Gradient Descent, SGD）"></a>随机梯度下降（Stochastic Gradient Descent, SGD）</h3><p>随机梯度下降法在计算优化函数的梯度时利用随机选择的<strong>一个样本数据</strong></p>
<p>迭代过程如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(max_iters):</span><br><span class="line">  	x = get_batch(x, <span class="number">1</span>)</span><br><span class="line">    y = get_batch(y, <span class="number">1</span>)</span><br><span class="line">		grad = gradient(loss_function, y, x, b_old)</span><br><span class="line">		b_new = b_old - <span class="keyword">lambda</span>* grad</span><br><span class="line">		<span class="keyword">if</span> distance(b_new, b_old) &lt; sup:</span><br><span class="line">				end</span><br><span class="line">		end</span><br></pre></td></tr></table></figure>
<p>其中sup为收敛精度</p>
<h3 id="小批量梯度下降法（Mini-batch-Gradient-Descent-MBGD）"><a href="#小批量梯度下降法（Mini-batch-Gradient-Descent-MBGD）" class="headerlink" title="小批量梯度下降法（Mini-batch Gradient Descent, MBGD）"></a>小批量梯度下降法（Mini-batch Gradient Descent, MBGD）</h3><p>小批量梯度下降法在计算优化函数的梯度时利用随机选择的<strong>一部分样本数据</strong>，SGD实际上是MBGD的一个特例：</p>
<p>迭代过程如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(max_iters):</span><br><span class="line">  	x = get_batch(x, batch_size)</span><br><span class="line">    y = get_batch(y, batch_size)</span><br><span class="line">		grad = gradient(loss_function, y, x, b_old)</span><br><span class="line">		b_new = b_old - <span class="keyword">lambda</span>* grad</span><br><span class="line">		<span class="keyword">if</span> distance(b_new, b_old) &lt; sup:</span><br><span class="line">				end</span><br><span class="line">		end</span><br></pre></td></tr></table></figure>
<p>其中sup为收敛精度</p>
<p>一般来说，我们常用MBGD而不是SGD</p>
<h3 id="梯度下降法方法比较"><a href="#梯度下降法方法比较" class="headerlink" title="梯度下降法方法比较"></a>梯度下降法方法比较</h3><div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>BGD</th>
<th>SGD</th>
<th>MBGD</th>
</tr>
</thead>
<tbody>
<tr>
<td>优点</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>缺点</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<h3 id="实际应用"><a href="#实际应用" class="headerlink" title="实际应用"></a>实际应用</h3><p>数据集：Automobile.csv(Stata附带数据集)</p>
<p>属性数：12</p>
<p>数据预览：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>price</strong></th>
<th><strong>mpg</strong></th>
<th><strong>rep78</strong></th>
<th><strong>headroom</strong></th>
<th><strong>trunk</strong></th>
<th><strong>weight</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>4099</td>
<td>22</td>
<td>3</td>
<td>2.5</td>
<td>11</td>
<td>2930</td>
</tr>
<tr>
<td>4749</td>
<td>17</td>
<td>3</td>
<td>3</td>
<td>11</td>
<td>3350</td>
</tr>
<tr>
<td>3799</td>
<td>22</td>
<td></td>
<td>3</td>
<td>12</td>
<td>2640</td>
</tr>
<tr>
<td>4816</td>
<td>20</td>
<td>3</td>
<td>4.5</td>
<td>16</td>
<td>3250</td>
</tr>
<tr>
<td>7827</td>
<td>15</td>
<td>4</td>
<td>4</td>
<td>20</td>
<td>4080</td>
</tr>
<tr>
<td>5788</td>
<td>18</td>
<td>3</td>
<td>4</td>
<td>21</td>
<td>3670</td>
</tr>
</tbody>
</table>
</div>
<p>为方便起见，我们以price为因变量，mpg为自变量拟合线性模型</p>
<p>首先先看下散点图（stata）：</p>
<p><img src="../images/20210101_Python实现线性回归_1.png" alt="avatar"></p>
<p><strong>批量梯度下降法代码</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.spatial <span class="keyword">import</span> distance</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinearRegression</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__add_constant</span>(<span class="params">self, x, constant=<span class="literal">True</span>, predict=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="keyword">if</span> x.ndim == <span class="number">1</span>:</span><br><span class="line">            x.shape = (<span class="built_in">len</span>(x), <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> constant:</span><br><span class="line">            cons = np.ones(<span class="built_in">len</span>(x))</span><br><span class="line">            cons.shape = (<span class="built_in">len</span>(x), <span class="number">1</span>)</span><br><span class="line">            x = np.hstack([cons, x])</span><br><span class="line">        <span class="keyword">elif</span> <span class="keyword">not</span> constant:</span><br><span class="line">            cons = np.zeros(<span class="built_in">len</span>(x))</span><br><span class="line">            cons.shape = (<span class="built_in">len</span>(x), <span class="number">1</span>)</span><br><span class="line">            x = np.hstack([cons, x])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> predict:</span><br><span class="line">            self.x_new = x</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__gradient_descent</span>(<span class="params">self, y, x, learning_rate=<span class="number">1e-8</span>, epsilon=<span class="number">1e-20</span>, max_iter=<span class="number">1000000</span></span>):</span></span><br><span class="line">        <span class="comment"># theta是回归系数向量</span></span><br><span class="line">        <span class="comment"># 不直接使用最小二乘法的原因是有可能x不满秩，无法求出其逆矩阵，而梯度下降法本质上和最小二乘法相同，因此使用该近似方法</span></span><br><span class="line">        np.random.seed(<span class="number">20000</span>)</span><br><span class="line">        theta = np.random.randn(x.shape[<span class="number">1</span>])</span><br><span class="line">        theta.shape = (<span class="built_in">len</span>(theta), <span class="number">1</span>)</span><br><span class="line">        y.shape = (<span class="built_in">len</span>(y), <span class="number">1</span>)</span><br><span class="line">        error = np.zeros(x.shape[<span class="number">1</span>])</span><br><span class="line">        theta.dtype = np.float_</span><br><span class="line">        st1 = []</span><br><span class="line">        st2 = []</span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">iter</span> <span class="keyword">in</span> <span class="built_in">range</span>(max_iter):</span><br><span class="line">            sum_error = x.transpose().dot(x.dot(theta) - y) / (<span class="number">2</span> * x.shape[<span class="number">0</span>])</span><br><span class="line">            sum_error.dtype = np.float_</span><br><span class="line"></span><br><span class="line">            theta -= learning_rate * sum_error</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> distance.euclidean(theta, error) &lt; epsilon:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                error = theta.copy()</span><br><span class="line">                st1.append(<span class="built_in">abs</span>(sum_error[<span class="number">0</span>]))</span><br><span class="line">                st2.append(<span class="built_in">abs</span>(sum_error[<span class="number">1</span>]))</span><br><span class="line">        </span><br><span class="line">        a = np.array(<span class="built_in">list</span>(<span class="built_in">range</span>(<span class="built_in">iter</span>+<span class="number">1</span>)))</span><br><span class="line">        b = np.array(st1)</span><br><span class="line">        c = np.array(st2)</span><br><span class="line">        print(a.shape, b.shape)</span><br><span class="line">        fig = plt.figure(<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># plt.plot(a, b)</span></span><br><span class="line">        plt.plot(a, c, c=<span class="string">&#x27;g&#x27;</span>)</span><br><span class="line">        plt.show()</span><br><span class="line">        </span><br><span class="line">        self.theta = theta</span><br><span class="line">        y_pre = x.dot(theta)</span><br><span class="line">        y_pre.dtype = np.float_</span><br><span class="line">        self.y_pre = y_pre</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__residual</span>(<span class="params">self, y, y_pre</span>):</span></span><br><span class="line">        self.res = y - y_pre</span><br><span class="line">        self.res.dtype = np.float_</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__r_square</span>(<span class="params">self, y, y_pre</span>):</span></span><br><span class="line">        sst = (y - y.mean()).transpose().dot((y - y.mean()))[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">        sse = (y_pre - y.mean()).transpose().dot((y_pre - y.mean()))[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># ssr = sst - sse</span></span><br><span class="line">        ssr = (y - y_pre).transpose().dot((y - y_pre))[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">        print(<span class="string">&quot;y.mean():&quot;</span>, y.mean())</span><br><span class="line">        print(sst)</span><br><span class="line">        print(sse)</span><br><span class="line">        print(ssr)</span><br><span class="line"></span><br><span class="line">        self.r2 = sse / sst</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">durbin_waston</span>(<span class="params">self</span>):</span></span><br><span class="line">        error_1 = self.res[<span class="number">1</span>:]</span><br><span class="line">        error_0 = self.res[:-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        error_s = error_1 - error_0</span><br><span class="line">        error_s.dtype = np.float_</span><br><span class="line">        error_s_sum = error_s.transpose().dot(error_s)</span><br><span class="line"></span><br><span class="line">        error_sum = self.res.transpose().dot(self.res)</span><br><span class="line"></span><br><span class="line">        dw = error_s_sum / error_sum</span><br><span class="line"></span><br><span class="line">        self.dw = dw[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, y, x, constant=<span class="literal">True</span>, learning_rate=<span class="number">1e-6</span>, epsilon=<span class="number">1e-8</span>, max_iter=<span class="number">300000</span></span>):</span></span><br><span class="line">        y.shape = (<span class="built_in">len</span>(y), <span class="number">1</span>)</span><br><span class="line">        self.iscons = constant</span><br><span class="line">        self.x = x</span><br><span class="line">        self.y = y</span><br><span class="line">        x_new = self.__add_constant(x, constant)</span><br><span class="line"></span><br><span class="line">        self.__gradient_descent(y, x_new, constant, learning_rate, epsilon, max_iter)</span><br><span class="line">        </span><br><span class="line">        self.__residual(y, self.y_pre)</span><br><span class="line">        self.__r_square(y, self.y_pre)</span><br><span class="line">        self.durbin_waston()</span><br><span class="line">        <span class="comment"># fig = plt.figure(1)</span></span><br><span class="line">        <span class="comment"># plt.scatter(x, y, c=&#x27;g&#x27;)</span></span><br><span class="line">        <span class="comment"># plt.plot(x, self.y_pre)</span></span><br><span class="line">        <span class="comment"># plt.show()</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">regression_report</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            print(<span class="string">&quot;residual:&quot;</span>, self.res)</span><br><span class="line">            print(<span class="string">&quot;intercept = &#123;&#125;, slope = &#123;&#125;&quot;</span>.<span class="built_in">format</span>(self.theta[<span class="number">0</span>], self.theta[<span class="number">1</span>:]))</span><br><span class="line">            print(<span class="string">&quot;r_square = &#123;&#125;&quot;</span>.<span class="built_in">format</span>(self.r2))</span><br><span class="line">            print(<span class="string">&quot;dw = &#123;&#125;&quot;</span>.<span class="built_in">format</span>(self.dw))</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">&quot;please fit a regression model&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, x_test</span>):</span></span><br><span class="line">        x_test = self.__add_constant(x_test, self.iscons, <span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> x_test.dot(self.theta)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    lm = LinearRegression()</span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;Automobile.csv&quot;</span>)</span><br><span class="line">    df = df.fillna(axis=<span class="number">0</span>, method=<span class="string">&#x27;ffill&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    x = df[[<span class="string">&#x27;mpg&#x27;</span>]]</span><br><span class="line">    y = df[<span class="string">&#x27;price&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    x = x.values</span><br><span class="line">    y = y.values</span><br><span class="line">    lm.fit(y, x)</span><br><span class="line">    lm.regression_report()</span><br></pre></td></tr></table></figure>
<p>设置学习率为1e-6，收敛精度为1e-8，最大迭代次数为300000</p>
<p>代码运行结果：</p>
<p>误差的收敛情况：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.spatial <span class="keyword">import</span> distance</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinearRegression</span>:</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__stochastic_gradient_descent</span>(<span class="params">self, y, x, learning_rate=<span class="number">1e-8</span>, epsilon=<span class="number">1e-20</span>, max_iter=<span class="number">1000000</span>, batch=<span class="number">64</span></span>):</span></span><br><span class="line">        <span class="comment"># theta是回归系数向量</span></span><br><span class="line">        <span class="comment"># 不直接使用最小二乘法的原因是有可能x不满秩，无法求出其逆矩阵，而梯度下降法本质上和最小二乘法相同，因此使用该近似方法</span></span><br><span class="line">        np.random.seed(<span class="number">20000</span>)</span><br><span class="line">        theta = np.random.randn(x.shape[<span class="number">1</span>])</span><br><span class="line">        theta.shape = (<span class="built_in">len</span>(theta), <span class="number">1</span>)</span><br><span class="line">        y.shape = (<span class="built_in">len</span>(y), <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        error = np.zeros(x.shape[<span class="number">1</span>])</span><br><span class="line">        theta.dtype = np.float_</span><br><span class="line">        st1 = []</span><br><span class="line">        st2 = []</span><br><span class="line">        print(<span class="built_in">type</span>(max_iter), max_iter)</span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">iter</span> <span class="keyword">in</span> <span class="built_in">range</span>(max_iter):</span><br><span class="line">            b = np.random.choice(x.shape[<span class="number">0</span>], batch)</span><br><span class="line">            random_x = x[b]</span><br><span class="line">            random_y = y[b]</span><br><span class="line">            </span><br><span class="line">            sum_error = random_x.transpose().dot(random_x.dot(theta) - random_y) / (<span class="number">2</span> * random_x.shape[<span class="number">0</span>])</span><br><span class="line">            sum_error.dtype = np.float_</span><br><span class="line"></span><br><span class="line">            theta -= learning_rate * sum_error</span><br><span class="line">            print(<span class="string">&quot;sum_error:&quot;</span>, sum_error)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> distance.euclidean(theta, error) &lt; epsilon:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                error = theta.copy()</span><br><span class="line">                st1.append(<span class="built_in">abs</span>(sum_error[<span class="number">0</span>]))</span><br><span class="line">                st2.append(<span class="built_in">abs</span>(sum_error[<span class="number">1</span>]))</span><br><span class="line">        </span><br><span class="line">        a = np.array(<span class="built_in">list</span>(<span class="built_in">range</span>(<span class="built_in">iter</span>+<span class="number">1</span>)))</span><br><span class="line">        b = np.array(st1)</span><br><span class="line">        c = np.array(st2)</span><br><span class="line">        </span><br><span class="line">        fig = plt.figure(<span class="number">1</span>)</span><br><span class="line">        plt.plot(a, c, c=<span class="string">&#x27;g&#x27;</span>)</span><br><span class="line">        plt.show()</span><br><span class="line">        self.theta = theta</span><br><span class="line">        y_pre = x.dot(theta)</span><br><span class="line">        y_pre.dtype = np.float_</span><br><span class="line">        self.y_pre = y_pre</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">    lm = LinearRegression()</span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;Automobile.csv&quot;</span>)</span><br><span class="line">    df = df.fillna(axis=<span class="number">0</span>, method=<span class="string">&#x27;ffill&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    x = df[[<span class="string">&#x27;mpg&#x27;</span>]]</span><br><span class="line">    y = df[<span class="string">&#x27;price&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    x = x.values</span><br><span class="line">    y = y.values</span><br><span class="line">    lm.fit(y, x)</span><br><span class="line">    lm.regression_report()</span><br></pre></td></tr></table></figure>
<p>设置学习率为1e-6，收敛精度为1e-8，最大迭代次数为300000</p>
<p>代码运行结果：</p>
<p>误差的收敛情况：</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><div id="refer-anchor-1"></div></p>
<ul>
<li>[1]  <a href="https://baike.baidu.com/item/梯度/13014729?fr=aladdin">百度百科-梯度</a></li>
</ul>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>statistics</tag>
        <tag>linear regression</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo转义符号</title>
    <url>/2020/12/27/20201227_Hexo%E8%BD%AC%E4%B9%89%E7%AC%A6%E5%8F%B7/</url>
    <content><![CDATA[<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">符号 转义字符             说明</span><br><span class="line">!    &amp;#33;              惊叹号</span><br><span class="line">”    &amp;#34;(&quot;)           双引号</span><br><span class="line">#    &amp;#35;              数字标志</span><br><span class="line">$    &amp;#36;              美元标志</span><br><span class="line">%    &amp;#37;              百分号</span><br><span class="line">&amp;    &amp;#38;(&amp;)           和</span><br><span class="line">‘    &#39;                  单引号</span><br><span class="line">(    &amp;#40;              小括号左边部分</span><br><span class="line">)    &amp;#41;              小括号右边部分</span><br><span class="line">*    &amp;#42;              星号</span><br><span class="line">+    &amp;#43;              加号</span><br><span class="line">&lt;    &amp;#60;(&lt;)           小于号</span><br><span class="line">&#x3D;    &amp;#61;              等于符号</span><br><span class="line">-    &amp;#45;(&amp;minus;)     减号</span><br><span class="line">&gt;    &amp;#62;(&gt;)           大于号</span><br><span class="line">?    &amp;#63;              问号</span><br><span class="line">@    &amp;#64;              Commercial at</span><br><span class="line">[    &amp;#91;              中括号左边部分</span><br><span class="line">\    &amp;#92;              反斜杠        </span><br><span class="line">]    &amp;#93;              中括号右边部分</span><br><span class="line">&#123;    &amp;#123;             大括号左边部分</span><br><span class="line">|    &amp;#124;             竖线</span><br><span class="line">&#125;    &amp;#125;             大括号右边部分</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo搭建过程存在的问题以及对应的解决办法(Mac OS)</title>
    <url>/2020/12/27/20201227_Hexo%E6%9C%AC%E5%9C%B0%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E9%97%AE%E9%A2%98%E9%9B%86/</url>
    <content><![CDATA[<h1 id="系统配置"><a href="#系统配置" class="headerlink" title="系统配置"></a>系统配置</h1><hr>
<p>MacBook Pro (16-inch, 2019)<br><strong>Processor</strong>：2.3 GHz 8-Core Intel Core i9<br><strong>Memory</strong>：16GB 2667 MHz DDR4<br><strong>Graphics</strong>：AMD Radeon Pro 5500M &amp;Intel UHD Graphics 630 1536 MB</p>
<h1 id="用hexo搭建本地博客的基本步骤"><a href="#用hexo搭建本地博客的基本步骤" class="headerlink" title="用hexo搭建本地博客的基本步骤"></a>用hexo搭建本地博客的基本步骤</h1><h2 id="1-安装Homebrew套件"><a href="#1-安装Homebrew套件" class="headerlink" title="1. 安装Homebrew套件"></a>1. 安装Homebrew套件</h2><hr>
<ul>
<li>官方安装命令：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/usr/bin/ruby -e <span class="string">&quot;<span class="subst">$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)</span>&quot;</span></span><br></pre></td></tr></table></figure></li>
<li>如遇到网速过慢的情况，可点击这里参看解决办法</li>
</ul>
<h2 id="2-安装Node-js"><a href="#2-安装Node-js" class="headerlink" title="2. 安装Node.js"></a>2. 安装Node.js</h2><hr>
<ul>
<li>安装命令<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">brew install node </span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="3-安装Hexo"><a href="#3-安装Hexo" class="headerlink" title="3. 安装Hexo"></a>3. 安装Hexo</h2><hr>
<ul>
<li>安装命令：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install -g hexo</span><br></pre></td></tr></table></figure></li>
<li>如遇到网速过慢的情况，可点击这里参看解决办法</li>
</ul>
<h2 id="4-配置Hexo"><a href="#4-配置Hexo" class="headerlink" title="4. 配置Hexo"></a>4. 配置Hexo</h2><hr>
<ul>
<li>在任意位置创建存放本地博客的文件夹，现假定在/Users/user下<ul>
<li>创建文件夹命令：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir &lt;your folder name&gt;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>进入博客文件夹：<ul>
<li>命令： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> &lt;your folder name&gt;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>依次键入以下命令：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo init</span><br><span class="line">npm install</span><br></pre></td></tr></table></figure></li>
<li>例外情况：<ul>
<li>若hexo版本为5.0及以上，安装部分主题会提示：&#34;&#123;&#37; extends &#39;_layout.swig&#39; &#37;&#125; &#123;&#37; import &#39;_macro/post.swig&#39; as post_template &#37;&#125;&#34;<ul>
<li>原因：swig需要自己手动安装(博主自己的版本为4.2.0，依旧需要手动安装)</li>
<li>解决办法：在博客文件夹下键入命令：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm i hexo-renderer-swig</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
</li>
<li>搭建成功的目录：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">   .</span><br><span class="line">├── _config.yml</span><br><span class="line">├── package.json</span><br><span class="line">├── scaffolds</span><br><span class="line">├── source</span><br><span class="line">|   ├── _drafts</span><br><span class="line">|   └── _posts</span><br><span class="line">└── themes</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="5-测试博客"><a href="#5-测试博客" class="headerlink" title="5. 测试博客"></a>5. 测试博客</h2><hr>
<ul>
<li>使用命令：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo s --debug  //启动hexo服务器，提示可以从localhost:4000访问，整个过程都可以看到调试信息</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="6-Hexo常用命令"><a href="#6-Hexo常用命令" class="headerlink" title="6. Hexo常用命令"></a>6. Hexo常用命令</h2><hr>
   <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo init       //将当前目录初始化为hexo站点</span><br><span class="line">hexo new &lt;new blog name&gt;   //新建一篇文章。如无特殊设置会放在/<span class="built_in">source</span>/_posts中</span><br><span class="line">hexo new page &lt;new page name&gt;  //新建一个网页。生成网页后的路径将在执行命令后显示，一般在/<span class="built_in">source</span>中</span><br><span class="line">default_layout 参数代替。如果标题包含空格的话，请使用引号括起来。</span><br><span class="line">hexo clean      // 清除缓存，如果对本地文件做了修改，同步到远程验证修改的效果之前，先clean，清除缓存</span><br><span class="line">hexo generate   // 简写hexo g，根据markdown文件生成静态文件</span><br><span class="line">hexo server     // 简写hexo s，启动本地hexo 服务器，默认localhost:4000可以访问</span><br><span class="line">hexo deploy     // 简写hexo d，将本地修改，部署到远端</span><br><span class="line">hexo version    // 简写hexo v，显示hexo版本</span><br></pre></td></tr></table></figure>
<h1 id="问题集"><a href="#问题集" class="headerlink" title="问题集"></a>问题集</h1><hr>
<h2 id="1-npm下载速度慢"><a href="#1-npm下载速度慢" class="headerlink" title="1. npm下载速度慢"></a>1. npm下载速度慢</h2><hr>
<p>原因：国内网下载国外数据<br>解决办法：更换镜像<br>三种方式：</p>
<ol>
<li>通过config命令<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm config <span class="built_in">set</span> registry https://registry.npm.taobao.org –global </span><br><span class="line">npm config <span class="built_in">set</span> disturl https://npm.taobao.org/dist –global</span><br></pre></td></tr></table></figure></li>
<li>命令行指定(推荐)<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm –registry https://registry.npm.taobao.org info underscore</span><br></pre></td></tr></table></figure></li>
<li>编辑 ~/.npmrc 加入下面内容<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">registry = https://registry.npm.taobao.org</span><br></pre></td></tr></table></figure>
<h2 id="2-categories和tags页面不显示"><a href="#2-categories和tags页面不显示" class="headerlink" title="2. categories和tags页面不显示"></a>2. categories和tags页面不显示</h2></li>
</ol>
<hr>
<p>原因：默认不显示categories和tags页面，<br>解决办法：如果需要的话需要利用上面的命令新建，具体做法是(默认现在位置在博客目录下)：</p>
<ol>
<li>在博客目录下键入以下命令：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo new page tags</span><br><span class="line">hexo new page categories</span><br></pre></td></tr></table></figure></li>
<li>打开source/tags/index.md，添加type: tags，如<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: tags</span><br><span class="line">date: 2020-12-27 03:12:33</span><br><span class="line">type: tags</span><br><span class="line">---</span><br></pre></td></tr></table></figure></li>
<li>打开source/categories/index.md，添加type: categories，如<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: categories</span><br><span class="line">date: 2020-12-27 03:12:33</span><br><span class="line">type: categories</span><br><span class="line">---</span><br></pre></td></tr></table></figure></li>
<li>打开scaffolds/draft.md，添加tags: &#123; &#123;tags &#125; &#125;，如:<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: &#123;&#123; title &#125;&#125;</span><br><span class="line">tags: &#123;&#123; tags &#125;&#125;</span><br><span class="line">---</span><br></pre></td></tr></table></figure></li>
<li>打开scaffolds/post.md，添加tags: &#123; &#123; tags &#125; &#125;，如：<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: &#123;&#123; title &#125;&#125;</span><br><span class="line">date: &#123;&#123; date &#125;&#125;</span><br><span class="line">tags: &#123;&#123; tags &#125;&#125;</span><br><span class="line">---</span><br></pre></td></tr></table></figure>
<h2 id="3-写hexo博客时报错Template-render-error-unknown-path"><a href="#3-写hexo博客时报错Template-render-error-unknown-path" class="headerlink" title="3. 写hexo博客时报错Template render error: (unknown path)"></a>3. 写hexo博客时报错Template render error: (unknown path)</h2></li>
</ol>
<hr>
<p>原因：文章中出现了hexo无法转义的字符<br>解决办法：使用转义符号，具体可参见<a href="/2020/12/27/20201227_Hexo转义符号/">Hexo转义字符</a></p>
<h2 id="4-使用Next主题，按照教程部署，打不开tags和categories"><a href="#4-使用Next主题，按照教程部署，打不开tags和categories" class="headerlink" title="4. 使用Next主题，按照教程部署，打不开tags和categories"></a>4. 使用Next主题，按照教程部署，打不开tags和categories</h2><hr>
<p>原因：教程有缺陷，出现了多余空格<br>解决办法：打开/themes/next/_config.yml<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">menu:</span><br><span class="line">   tags: &#x2F; || tags</span><br><span class="line">改为：</span><br><span class="line">menu:</span><br><span class="line">   tags: &#x2F;|| tags</span><br><span class="line">其他同理</span><br></pre></td></tr></table></figure></p>
<h2 id="5-文章多标签设置"><a href="#5-文章多标签设置" class="headerlink" title="5. 文章多标签设置"></a>5. 文章多标签设置</h2><hr>
<p>原因：没有参照官方文档<br>解决办法：tags: [tag1,tag2,…,tagn] (推荐)</p>
<h2 id="6-上一页-下一页显示不正确"><a href="#6-上一页-下一页显示不正确" class="headerlink" title="6. 上一页/下一页显示不正确"></a>6. 上一页/下一页显示不正确</h2><p>点击上一页和下一页有效果，但是显示的是’<i class="fa fa-angle-left">&lt;/i&gt;’和’<i class="fa fa-angle-right"></i>‘，说明有上一页和下一页的效果，只是图标显示有问题，需要将<br>themes/next/layout/_partials/pagination.swig的代码替换成</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">&#123;% if page.prev or page.next %&#125;</span><br><span class="line">  <span class="tag">&lt;<span class="name">nav</span> <span class="attr">class</span>=<span class="string">&quot;pagination&quot;</span>&gt;</span></span><br><span class="line">    &#123;&#123;</span><br><span class="line">      paginator(&#123;</span><br><span class="line">        prev_text: &#x27;上一页&#x27;,</span><br><span class="line">        next_text: &#x27;下一页&#x27;,</span><br><span class="line">        mid_size: 1</span><br><span class="line">      &#125;)</span><br><span class="line">    &#125;&#125;</span><br><span class="line">  <span class="tag">&lt;/<span class="name">nav</span>&gt;</span></span><br><span class="line">&#123;% endif %&#125;·</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>hexo</tag>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2020/12/27/20201227_hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
</search>
